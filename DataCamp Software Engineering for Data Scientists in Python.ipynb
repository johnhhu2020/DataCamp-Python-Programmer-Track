{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfaa83a6-afce-4562-9c7e-3c4afc231451",
   "metadata": {},
   "source": [
    "## Software Engineering for Data Scientists in Python\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de164c77-4ce2-4bc2-9dc4-a7feec9d4f5c",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "\n",
    "Data scientists can experience huge benefits by learning concepts from the field of software engineering, allowing them to more easily reutilize their code and share it with collaborators. In this course, you'll learn all about the important ideas of modularity, documentation, & automated testing, and you'll see how they can help you solve Data Science problems quicker and in a way that will make future you happy. You'll even get to use your acquired software engineering chops to write your very own Python package for performing text analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804bad5c-709c-4ac0-b489-1293dc2e5f51",
   "metadata": {},
   "source": [
    "##  Software Engineering & Data Science\n",
    "Free\n",
    "0%\n",
    "\n",
    "Why should you as a Data Scientist care about Software Engineering concepts? Here we'll cover specific Software Engineering concepts and how these important ideas can revolutionize your Data Science workflow!\n",
    "\n",
    "    Python, data science, & software engineering    50 xp\n",
    "    The big ideas    50 xp\n",
    "    Python modularity in the wild    100 xp\n",
    "    Introduction to packages & documentation    50 xp\n",
    "    Installing packages with pip    50 xp\n",
    "    Leveraging documentation    100 xp\n",
    "    Conventions and PEP 8    50 xp\n",
    "    Using pycodestyle    100 xp\n",
    "    Conforming to PEP 8    100 xp\n",
    "    PEP 8 in documentation    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98921ae-b777-4ea3-b441-e6a6bc9cf37e",
   "metadata": {},
   "source": [
    "##  Writing a Python Module\n",
    "0%\n",
    "\n",
    "Become a fully fledged Python package developer by writing your first package! You'll learn how to structure and write Python code that you can be installed, used, and distributed just like famous packages such as NumPy and Pandas.\n",
    "\n",
    "    Writing your first package    50 xp\n",
    "    Minimal package requirements    50 xp\n",
    "    Naming packages    100 xp\n",
    "    Recognizing packages    100 xp\n",
    "    Adding functionality to packages    50 xp\n",
    "    Adding functionality to your package    100 xp\n",
    "    Using your package's new functionality    100 xp\n",
    "    Making your package portable    50 xp\n",
    "    Writing requirements.txt    100 xp\n",
    "    Installing package requirements    50 xp\n",
    "    Creating setup.py    100 xp\n",
    "    Listing requirements in setup.py    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7e497-6de2-463e-b57e-77e86fcc15c9",
   "metadata": {},
   "source": [
    "##  Utilizing Classes\n",
    "0%\n",
    "\n",
    "Object Oriented Programming is a staple of Python development. By leveraging classes and inheritance your Python package will become a much more powerful tool for your users.\n",
    "\n",
    "    Adding classes to a package    50 xp\n",
    "    Writing a class for your package    100 xp\n",
    "    Using your package's class    100 xp\n",
    "    Adding functionality to classes    50 xp\n",
    "    Writing a non-public method    100 xp\n",
    "    Using your class's functionality    100 xp\n",
    "    Classes and the DRY principle    50 xp\n",
    "    Using inheritance to create a class    100 xp\n",
    "    Adding functionality to a child class    100 xp\n",
    "    Using your child class    100 xp\n",
    "    Multilevel inheritance    50 xp\n",
    "    Exploring with dir and help    100 xp\n",
    "    Creating a grandchild class    100 xp\n",
    "    Using inherited methods    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7beea6-2cdf-4a74-af25-906279bdc7d5",
   "metadata": {},
   "source": [
    "##  Maintainability\n",
    "0%\n",
    "\n",
    "You've now written a fully functional Python package for text analysis! To make maintaining your project as easy as possible we'll leverage best practices around concepts such as documentation and unit testing.\n",
    "\n",
    "    Documentation    50 xp\n",
    "    Identifying good comments    100 xp\n",
    "    Identifying proper docstrings    100 xp\n",
    "    Writing docstrings    100 xp\n",
    "    Readability counts    50 xp\n",
    "    Using good function names    100 xp\n",
    "    Using good variable names    100 xp\n",
    "    Refactoring for readability    100 xp\n",
    "    Unit testing    50 xp\n",
    "    Using doctest    100 xp\n",
    "    Using pytest    100 xp\n",
    "    Documentation & testing in practice    50 xp\n",
    "    Documenting classes for Sphinx    100 xp\n",
    "    Identifying tools    50 xp\n",
    "    Final Thoughts    50 xp \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd98d7-4bd1-489b-95dc-869b74bab5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96f6e84b-1d18-43fa-aad6-4e5e2a275ae1",
   "metadata": {},
   "source": [
    "## Python, data science, & software engineering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Welcome to the course \"Software Engineering for Data Scientists in Python\".  My name is Adam Spannbauer.  I'm a Data Scientist from Tennessee who likes to code in both R and Python.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "In this course, we'll be covering aoftware engineering concepts that can revolutioniza your Data Science workflow.  SO why should a Data Scientistcare about the principles of Software Engineering?  Many Data Scientists, like myself, start in the world of math & statistics.  And soon after, you learn that communicating these technical ideals is just as important as understanding them yourself.  However, many Data Scientists are self-taught programmers who see coding as a means to an end; its just a step to create a model or run a simulation.  But in reality, SOftware Engineering is a valuable skill that needs to be learned and practiced.  \n",
    "# *******************************************************************************************************************\n",
    "\n",
    "This course will help you buildyour software engineering skills by introducing some very important concepts.  Three topics in particular that we'll coverare Modularity, Documentation, and Testing.  \n",
    "\n",
    "Another topic worth mentioning is Version Control.  We won't be covering it in this course, but I recommend checking out the related DataCamp course to learn more about this powerful tool.  \n",
    "\n",
    "\n",
    "Lets define each of these comcepts that we'll be covering.  First was Modularity.  To introduce modular code lets start by defining what its not.  Non-modular code can take the form of long, complicated, hard to read script and functions.  Programming becomes less complex when your code is divided into shorter functional units, and this is the whole idea behind modularity.  \n",
    "\n",
    "With modular code, not only does code become more readable but it becomes easier to fix when something breaks.  Additionally, modular code is easier to take along with you to your next project; which allows you to save time by avoiding re-solving problems you've already solved in a previous project.  \n",
    "\n",
    "We can write modular code in Python by leveraging packages, classes, and mothods.  In below example code, we import Pandas package.  We create a new object using the powerful DataFramme class from Pandas.  Finally, we use the convenient plot method that comes built into the DataFrame class.  Later in this course, you'll write a fully functional Python package using all these concepts to perform text analysis.  \n",
    "\n",
    "\n",
    "If you work on a team or if you ever publish a project, then other people will need to read your code, and sometimes, the other person is just future you.  Both future you and other people will have an easier time reading your project if you use a good documentation practices.  \n",
    "\n",
    "In this course, we'll cover how to use \"comments\", \"docstrings\", and \"self-documenting code\" to document your Data Science Python projects.  A project using all these techniques can save a lot of confusion and frustration for everyone who touches the code.  \n",
    "\n",
    "The last Software Engineering concept we'll touch on is Testing.  One thing everyone learns is that people make mistakes.  That's why pencils have erasers, why computers have spellcheck, and why software needs tests.  Often times Data Scientists will write some code, test it in the console once, and then never test it again.  Its definitely worthwhile to perform these manual texts, but leveraging tools like the \"pytest\" package can automatically run and re-run your tests to ensure your code is working as intended even after new functionality.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bcf22d-004b-4c16-85a7-82c30a40a969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'x': [1, 2, 3, 4], \n",
    "        'y': [20.1, 62.5, 34.8, 42.7]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.plot('x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3a9a4-a20c-4c9c-9dfd-768663611e0f",
   "metadata": {},
   "source": [
    "## The big ideas\n",
    "\n",
    "Which 3 software engineering concepts included in this course can help Data Scientists save time, collaborate, and write better code?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Big Data, Machine Learning, & Algorithms\n",
    "    press\n",
    "    1\n",
    "#    Modularity, Documentation, & Automated Testing\n",
    "    press\n",
    "    2\n",
    "    R, Python, & SQL\n",
    "    press\n",
    "    3\n",
    "    Google, StackOverflow, & Luck\n",
    "    press\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd980dc-0f3e-4b4e-bec8-5a2ccd7c5cf7",
   "metadata": {},
   "source": [
    "## Python modularity in the wild\n",
    "\n",
    "In the slides, we covered 3 ways that you can write modular code with Python: packages, classes, and methods. For reference, you can see the example code we reviewed below.\n",
    "\n",
    "# Import the pandas PACKAGE\n",
    "import pandas as pd\n",
    "\n",
    "# Create some example data\n",
    "data = {'x': [1, 2, 3, 4], \n",
    "        'y': [20.1, 62.5, 34.8, 42.7]}\n",
    "\n",
    "# Create a dataframe CLASS object\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use the plot METHOD\n",
    "df.plot('x', 'y')\n",
    "\n",
    "In this exercise, you'll utilize a class & a method from the popular package numpy.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "#    Complete the import statement to load the numpy package.\n",
    "#    Use numpy's array class to define arr.\n",
    "#    Use arr's \".sort()\" method to sort the numpy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7000d4-eded-46ea-9e73-64ce2f78fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# import the numpy package\n",
    "import ____ as np\n",
    "\n",
    "# create an array class object\n",
    "arr = np.____([8, 6, 7, 5, 3, 0, 9])\n",
    "\n",
    "# use the sort method\n",
    "arr.____()\n",
    "\n",
    "# print the sorted array\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b0631-9539-49f5-abfc-686007a81d3e",
   "metadata": {},
   "source": [
    "## Introduction to packages & documentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**You've now learned some important Software Engineering concepts.  We're now going to look at how beneficial these concepts can be as a user of Python open source software.  Namely, we're going to investigate packages.  We'll cover how to install packages from the Python Package Index, and we'll see how these packages leverage software engineering concepts we've covered.  Later in this course, we'll talk more about the Python Package Index, or PyPi for short, but for now, all you need to know is that PyPi gives us an easy platform to leverage published packages.  \n",
    "\n",
    "Thanks to packages being modular, we can easily install them from PyPi using a tool called \"pip\".  The \"pip\" is actually a recrusive acronym that stands for Pip Installs Packages, and it does just that.  The practice of leveraging pip install can save a lot of time and lets us aviod reworking problems that have already been solved and packaged by some smart membersof the Python community.  \n",
    "\n",
    "\n",
    "If we wanted to install the popular package NumPy we conveniently use the command \"pip install numpy\".  Barring any unexpected issues we now have NumPy installed and we can leverage all the benefitsthat come with this powerful package.  Note that pip will also install a package's dependencies as long as they're on PyPi.  However, in some cases, a package's dependencies might require a little extra work.  \n",
    "\n",
    "So how do we leverage NumPy's features?  Again thanks to good software engineering, NumPy has excellent documentation available both on the web and in the package itself.  Here we'll focus on the documentation shipped with the package.  Lets say we want to count the number of work days of in the year 2020.  NumPy provides the function \"np.busday_count()\" that can help us accomplish this, but how do we use it?  \n",
    "\n",
    "To view a function's documentation we can use the function \"help()\".  Below is the syntax we can use to learn more about NumPy's \".busday_count()\" method.  And we can see the response to our call for help.  Note that the output has been truncated in the slides.  From this documentation, we see  description of the function, its parameters, and how we can expect as output.  Additionally, we see an example that perfectly matchesour described use case.  \n",
    "\n",
    "We just saw that we can use \"help()\" to see a methods documentation, but we can also call helpon any object in Python.  We can call \"help()\" on the NumPy package to see some high-level documentation on what functionality it provides.  And we can call \"help()\" on an integer, from the output, we can read up on Python's integer class.  As we can tell, having this documentation can be invaluable to users like you and me.  But sometimes you might call \"help()\" on an object and see that there isn't any documentation.  Its up to developer to include these helpful tidbits.  \n",
    "\n",
    "Including documentation for your packages, classes and methods will make using your code much easier.  Its important to remember that future-you is also a user who will benefit from this documentation.  \n",
    "\n",
    "\n",
    "Believe me, documenting your code, even if you're the only user, can save a lot of wasted time and headaches.  I've personally suffered through relearning how to use code that I wrote, but this is totally preventable with good documentation.  \n",
    "\n",
    "We covered how to pip packages and how to read documentation using \"help()\".  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cdce76d5-29e3-413f-a1f7-4e59f0d06eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#help(np.busday_count)\n",
    "\n",
    "np.busday_count('2020-01-01', '2020-12-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "efc9e95c-32f1-4b9c-997f-a4740224c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(np)\n",
    "\n",
    "#help(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1492a-9159-44d9-95ac-fbc76134b2f0",
   "metadata": {},
   "source": [
    "## Installing packages with pip\n",
    "\n",
    "Which of the below commands could you run in your shell to install the package numpy with pip?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "#    pip install numpy\n",
    "    press\n",
    "    1\n",
    "    pip INSTALL numpy\n",
    "    press\n",
    "    2\n",
    "    install numpy pip\n",
    "    press\n",
    "    3\n",
    "    pip --upgrade numpy\n",
    "    press\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c61f2-8c13-423b-b987-bb294cc8cf2c",
   "metadata": {},
   "source": [
    "## Leveraging documentation\n",
    "\n",
    "When writing code for Data Science, it's inevitable that you'll need to install and use someone else's code. You'll quickly learn that using someone else's code is much more pleasant when they use good software engineering practices. In particular, good documentation makes the right way to call a function obvious. In this exercise you'll use python's help() method to view a function's documentation so you can determine how to correctly call a new method.\n",
    "\n",
    "The list words has been loaded in your session.\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "\n",
    "    Question 1\n",
    "    View the documentation of the \"Counter.most_common()\" method using the help() function. Note, you need to run the import statement before completing this step.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Correctly call Counter.most_common() by reading its documentation.\n",
    "    Print the results stored in top_5_words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d1ad89-1f75-481f-8c4b-22747b12402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function most_common in module collections:\n",
      "\n",
      "most_common(self, n=None)\n",
      "    List the n most common elements and their counts from the most\n",
      "    common to the least.  If n is None, then list all element counts.\n",
      "    \n",
      "    >>> Counter('abracadabra').most_common(3)\n",
      "    [('a', 5), ('b', 2), ('r', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "help(Counter.most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707edc-e9f9-4a78-a6c4-a4d6b0a8c234",
   "metadata": {},
   "source": [
    "## Conventions and PEP 8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great work on those exercises, In our short time together, we've seen how helpful the Python community can be.  Not only have they provided some excellent packages for us to use, but they've also provided documentation to help us use them.  Something you probably know from real life is that different cultures and communities follow different guildlines that can help them run smoothly.  \n",
    "\n",
    "For example this can be seen in different greetings, depending on which community setting you're in, it might make sense to say hwllo by shaking hands, bowing, or bumping fists.  These unwritten rules are knownas social conventions.  The world of Software Engineering also has conventions that differ based on the langurage and community.  Luckily for Pythonistas, these conventions are't unwritten.  \n",
    "\n",
    "We can turn to Python Enhancement Protocol 8 or PEP 8.  PEP 8 is the defacto Style Guide for Python Code.  Lt lets us know how to formatour code to be as readable as possible, and to quote PEP 8, \"code is read much often that it is written\".  So readability is not something that should be overlooked.  Lets see an example.  \n",
    "\n",
    "Herewe have some code that violates PEP 8 best practices.  To put it simply, the code here is hard to read.  A few problems are: The module import isn't at the top of the file, the spacing and indentation is inconsistent, and the lack of line breaks makes it difficult to tell when one idea finishes and the next one begins.  Even without knowing the specific PEP 8 rules being broken, you can probably tell this isn't the most readable chunk of code.  Lets see that same chunk of code looks like after being rewritten to conform to PEP 8.  Much better.  \n",
    "\n",
    "By following the agreed-upon rulesin PEP 8 and using whitespace appropriately, this code become much more readable despite accomplishing the same exact task.  So how is it possible to keep up with the many rules defined in PEP 8?  Thankfully for you and me, there are tools that can check your code for you just like a spellchecker.  \n",
    "\n",
    "# \"pycodestyle\" package help you check violation in Python\n",
    "Personally, I use the IDE that flags violations as soon as I write a bad line of code, but there are other options.  One in particular that you'll be exposed to in this course is the \"pycodestyle\" package.  The \"pycodestyle\" can check code in multiple files at once and it outputs descriptions of the violations along with information to let you know exactly where you need to go to fix the issues.  \n",
    "\n",
    "Here is some example code on how to install and use \"pycodestyle\" package from the shell.  As you'll see in the exercise later you can also run \"pycodestyle\" from a Python script.  Below I use the command line interface to check the contents of the file \"sample_pycodestyle.py\" that contains our poorly formatted code from before.  Note that the output we see on this slide has been truncated.  \n",
    "\n",
    "The output shows us the exact location of any violationsby showing the \"file name\", \"line number\", and \"column number\" where the problem occurred.  Note that the output does not use zero based indexing.  Additionally, pycodestyle output human readable description of the PEP 8 violationand an error code.  A complete list of pycodestyle's possible error codes can be seen in the packages documentation.  \n",
    "\n",
    "We'v covered the importance of PEP 8 and how it can improve your code's readability.  \n",
    "\n",
    "\n",
    "       Line number |         | Error description\n",
    "# dict_to_array.py:9:1: E402 module level importnot at the top of file\n",
    "  | File name        |Column number\n",
    "                        |Error code\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818e10c8-cc5a-4dec-9bea-f90f5a2f2c7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (500062613.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_21848/500062613.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    x = np.array(d.values())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#define our data\n",
    "my_dict = {\n",
    "    'a': 10, \n",
    "'b': 3, \n",
    "    'c'  :   4, \n",
    "          'd': 7}\n",
    "#import needed package\n",
    "import numpy as np\n",
    "#helper function\n",
    "def DictToArray(d):\n",
    "    \"\"\"Convert dictionary values to array\"\"\"\n",
    "    #extract values and convert\n",
    "                x = np.array(d.values())\n",
    "                return x\n",
    "    \n",
    "print(DictToArray(my_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12c82d6b-a660-499d-8194-2cd2114eec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([10, 3, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "# Import needed package\n",
    "import numpy as np\n",
    "\n",
    "# Define our data \n",
    "my_dict = {'a': 10, 'b': 3, 'c': 4, 'd': 7}\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def dict_to_array(d):\n",
    "    \"\"\"Convert dictionary values to numpy array\"\"\"\n",
    "    # Extract values and convert\n",
    "    x = np.array(d.values())\n",
    "    return x\n",
    "\n",
    "\n",
    "print(dict_to_array(my_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb999c-c456-4d59-9c99-9f2750c31d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(py39) jhu@debian:~/.virtual_environments$ pycodestyle sample_pycodestyle.py \n",
    "sample_pycodestyle.py:5:1: E402 module level import not at top of file\n",
    "sample_pycodestyle.py:8:1: E302 expected 2 blank lines, found 1\n",
    "sample_pycodestyle.py:14:1: E305 expected 2 blank lines after class or function definition, found 1\n",
    "sample_pycodestyle.py:16:1: E901 TokenError: EOF in multi-line statement\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat sample_pycodestyle.py \n",
    "# define our data\n",
    "my_dict = {'a': 10, 'b': 3, 'c': 4, 'd': 7}\n",
    "\n",
    "# import needed package\n",
    "import numpy as np\n",
    "\n",
    "# helper function\n",
    "def DictToArray(d):\n",
    "    \"\"\"Convert dictionary values to array\"\"\"\n",
    "    # extract values and convert\n",
    "    x = np.array(d.values())\n",
    "    return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DictToArray(my_dict\n",
    "(py39) jhu@debian:~/.virtual_environments$ \n",
    "\n",
    "\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ pycodestyle sample_pycodestyle.py \n",
    "sample_pycodestyle.py:6:1: E402 module level import not at top of file  #############################################\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat sample_pycodestyle.py \n",
    "# define our data\n",
    "my_dict = {'a': 10, 'b': 3, 'c': 4, 'd': 7}\n",
    "\n",
    "\n",
    "# import needed package\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# helper function\n",
    "def DictToArray(d):\n",
    "    \"\"\"Convert dictionary values to array\"\"\"\n",
    "    # extract values and convert\n",
    "    x = np.array(d.values())\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DictToArray(my_dict)\n",
    "(py39) jhu@debian:~/.virtual_environments$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfbef0-a180-47a2-ba65-80c9df493e48",
   "metadata": {},
   "source": [
    "## Using pycodestyle\n",
    "\n",
    "We saw earlier that pycodestyle can be run from the command line to check a file for PEP 8 compliance. Sometimes it's useful to run this kind of check from a Python script.\n",
    "\n",
    "In this exercise, you'll use pycodestyle's \"StyleGuide\" class to check multiple files for PEP 8 compliance. Both files accomplish the same task, but they differ greatly in formatting and readability. You can view the contents of the files by following their links below.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Import the \"pycodestyle\" package.\n",
    "#    Create an instance of \"StyleGuide()\" class named \"style_checker\".\n",
    "#    There are two files that we'll be checking; they're named 'nay_pep8.py' and 'yay_pep8.py'. Pass a list containing these file names to our style_checker's \".check_files\" method.\n",
    "    print() the results of our style check to the console. Make sure to read the output!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cbcf4-409d-4314-89a3-077e15d337ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycodestyle\n",
    "\n",
    "\n",
    "style_checker = pycodestyle.StyleGuide()  ###########################################################################\n",
    "\n",
    "check_files = ['nay_pep8.py', 'yay_pep8.py']\n",
    "\n",
    "output = style_checker.check_files(check_files)  ####################################################################\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be249259-b9f1-4e9a-a087-d25b38c4b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi_lists1.py:4:5: E265 block comment should start with '# '\n",
      "bmi_lists1.py:5:5: E265 block comment should start with '# '\n",
      "sample_pycodestyle.py:6:1: E402 module level import not at top of file\n",
      "<pycodestyle.StandardReport object at 0x7fdecea4c820>\n"
     ]
    }
   ],
   "source": [
    "import pycodestyle\n",
    "\n",
    "style_checker = pycodestyle.StyleGuide()\n",
    "\n",
    "check_files = ['bmi_lists1.py', 'sample_pycodestyle.py']\n",
    "\n",
    "outcome = style_checker.check_files(check_files)\n",
    "\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7108bf5-a5e1-4ab1-b64f-f1f136828adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StyleGuide in module pycodestyle:\n",
      "\n",
      "class StyleGuide(builtins.object)\n",
      " |  StyleGuide(*args, **kwargs)\n",
      " |  \n",
      " |  Initialize a PEP-8 instance with few options.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  check_files(self, paths=None)\n",
      " |      Run all checks on the paths.\n",
      " |  \n",
      " |  excluded(self, filename, parent=None)\n",
      " |      Check if the file should be excluded.\n",
      " |      \n",
      " |      Check if 'options.exclude' contains a pattern matching filename.\n",
      " |  \n",
      " |  get_checks(self, argument_name)\n",
      " |      Get all the checks for this category.\n",
      " |      \n",
      " |      Find all globally visible functions where the first argument\n",
      " |      name starts with argument_name and which contain selected tests.\n",
      " |  \n",
      " |  ignore_code(self, code)\n",
      " |      Check if the error code should be ignored.\n",
      " |      \n",
      " |      If 'options.select' contains a prefix of the error code,\n",
      " |      return False.  Else, if 'options.ignore' contains a prefix of\n",
      " |      the error code, return True.\n",
      " |  \n",
      " |  init_report(self, reporter=None)\n",
      " |      Initialize the report instance.\n",
      " |  \n",
      " |  input_dir(self, dirname)\n",
      " |      Check all files in this directory and all subdirectories.\n",
      " |  \n",
      " |  input_file(self, filename, lines=None, expected=None, line_offset=0)\n",
      " |      Run all checks on a Python source file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pycodestyle.StyleGuide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0835f5-9b77-4845-a3ab-6893ab937eca",
   "metadata": {},
   "source": [
    "## Conforming to PEP 8\n",
    "\n",
    "As we've covered, there are tools available to check if your code conforms to the PEP 8 guidelines. One possible way to stay compliant is to use an IDE that warns you when you accidentally stray from the style guide. Another way to check code is to use the pycodestyle package.\n",
    "\n",
    "The results below show the output of running pycodestyle check against the code shown in your editor. The leading number in each line shows how many occurrences there were of that particular violation.\n",
    "\n",
    "my_script.py:2:2:  E225 missing whitespace around operator\n",
    "my_script.py:2:7:  E231 missing whitespace after ','\n",
    "my_script.py:2:9:  E231 missing whitespace after ','\n",
    "my_script.py:5:7:  E201 whitespace after '('\n",
    "my_script.py:5:11: E202 whitespace before ')'\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Leverage the output of pycodestyle to edit the code to be compliant with PEP 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc5740-55b9-4628-bfd5-b773d1be5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data to x\n",
    "x=[8,3,4]\n",
    "\n",
    "# Print the data\n",
    "print(   x )\n",
    "\n",
    "\n",
    "Hint\n",
    "\n",
    "    PEP 8 advises that there should be 1 and only 1 space after commas when defining lists.\n",
    "    PEP 8 advises that there shouldn't be spaces around ( & ) when calling functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4fd8f-1e1b-4c99-ad02-786bbe42164f",
   "metadata": {},
   "source": [
    "## PEP 8 in documentation\n",
    "\n",
    "So far we've focused on how PEP 8 affects functional pieces of code. There are also rules to help make comments and documentation more readable. In this exercise, you'll be fixing various types of comments to be PEP 8 compliant.\n",
    "\n",
    "The result of a pycodestyle style check on the code can be seen below.\n",
    "\n",
    "# my_script.py:2:15: E261 at least two spaces before inline comment\n",
    "# my_script.py:5:16: E262 inline comment should start with '# '\n",
    "# my_script.py:11:1: E265 block comment should start with '# '\n",
    "# my_script.py:13:2: E114 indentation is not a multiple of four (comment)\n",
    "my_script.py:13:2: E116 unexpected indentation (comment)\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Leverage the output of pycodestyle to edit the code's comments to be compliant with PEP 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be90892-38da-433b-9f7b-84b108e07a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_phrase(phrase, polite=True, shout=False):\n",
    "    if polite:  # It's generally polite to say please\n",
    "        phrase = 'Please ' + phrase\n",
    "\n",
    "    if shout:  # All caps looks like a written shout\n",
    "        phrase = phrase.upper() + '!!'\n",
    "\n",
    "    print(phrase)\n",
    "\n",
    "\n",
    "# Politely ask for help\n",
    "print_phrase('help me', polite=True)\n",
    "# Shout about a discovery\n",
    "print_phrase('eureka', shout=True)\n",
    "\n",
    "\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ pycodestyle print_phrase.py   # Interesting here\n",
    "print_phrase.py:13:2: E114 indentation is not a multiple of 4 (comment)  ############################################\n",
    "print_phrase.py:13:2: E116 unexpected indentation (comment)\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat print_phrase.py \n",
    "def print_phrase(phrase, polite=True, shout=False):\n",
    "    if polite:  # It's generally polite to say please\n",
    "        phrase = 'Please ' + phrase\n",
    "\n",
    "    if shout:  # All caps looks like a written shout\n",
    "        phrase = phrase.upper() + '!!'\n",
    "\n",
    "    print(phrase)\n",
    "\n",
    "\n",
    "# Politely ask for help\n",
    "print_phrase('help me', polite=True)\n",
    " # Shout about a discovery\n",
    "print_phrase('eureka', shout=True)\n",
    "(py39) jhu@debian:~/.virtual_environments$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dcb3f4-1ad4-4774-981b-43e816d23981",
   "metadata": {},
   "source": [
    "## Writing your first package\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Up to this point, we've covered some important topics for Software Engineering in Python.  Now we're going to get our hands dirty and put these ideas into practice by building a Python package from ground up.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# We've seen how useful packages can be for easily importing functionality into a workflow, but what is under the covers?  How do we make one ourselves?  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "A minimal Python package consists of 2 elements: a directory and a Python file.  You can see the basic structure under your JupyterLab working environment.  The name of the directory will be the name of the package, but how should you name it?  We can turn to PEP 8 for some guildance.  \n",
    "# *******************************************************************************************************************\n",
    "To paraphrase, PEP 8 states that packages should have short, all-lowercase names.  The use of underscores in a package name is discouraged, but you can and should use them if it improves readability.  Outside of this, you have freedom to brand as you'd like.  I'd suggest pisking a name that convers the functionality of the package.  \n",
    "# *******************************************************************************************************************\n",
    "The file in our newly branded directory doesn't have any flexibility in naming.  We must name it \"__init__.py\".  This file lets Python know that the directory we created is a package.  And thats it.  With this structure we've created a package that we can import just like we would import NumPy or any other package.  \n",
    "\n",
    "Note that as of Python version 3.3, any directory can be imported as if it were a package without error even if it doesn't follow this structure.  Earlier versions of Python would throw an error if you tried to import an improperly formatted package.  Even though a directory might import without error, you will run into issues if you do not follow this structure.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "So how do we import our package?  Before we look at some code lets establish where our script is relative to our new packages.  We'll be working in the \"my_script.py\" file that's in the same location as our package directory.  With all the setup we've done so far, importing the package is a breeze.  At the top of our script, we can use import my_package.  Just for an added bonus, lets check out what happens if we try to call help on our package.  We get some minimal information with Python letting us know that it is indeed a package and additionally we see the location of our __init__.py file.  \n",
    "\n",
    "As we previously covered, its up to the developer to add in useful documentation to be printed whenever a user calls help.  Later we will be going over how we can add this documentation as well as implementing some functionality to make our package more useful.  We just covered how to make a Python package skeleton.  This is an important concept that will serve as a funcation for all the useful packages you'll be writing in the future.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "working_directory\n",
    "  my_script.py\n",
    "  \n",
    "  package_name\n",
    "    __init__.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6591eb-5bb8-4b60-813a-45ce3cc590c6",
   "metadata": {},
   "source": [
    "## Minimal package requirements\n",
    "\n",
    "What are the minimal requirements to make an import-able python package?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    A directory named __init__.\n",
    "    press\n",
    "    1\n",
    "    A monthly stipend from a research grant.\n",
    "    press\n",
    "    2\n",
    "    A directory with modular, documented, tested code.\n",
    "    press\n",
    "    3\n",
    "#    A directory with a blank file named __init__.py.\n",
    "    press\n",
    "    4\n",
    "    \n",
    "Hint\n",
    "\n",
    "    The requirements for a package include a single python file and it's location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794524f5-62bc-4afb-b0de-81da15742a85",
   "metadata": {},
   "source": [
    "## Naming packages\n",
    "\n",
    "We covered the PEP 8 guidelines for naming packages. In this exercise, you'll use that knowledge to identify a package following the requirements.\n",
    "\n",
    "For additional reference, you can view the PEP 8 section on package naming here\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    The possible package names to import are the following: \"text_analyzer\", \"textAnalyzer\", \"TextAnalyzer\", & \"__text_analyzer__\".\n",
    "    import the package from the list above that follows the PEP 8 naming conventions.\n",
    "\n",
    "Hint\n",
    "\n",
    "    To import the package use a command with the format import package_name.\n",
    "    View the linked documentation to PEP 8 to remind yourself of the package naming conventions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3fc04-1ea5-4fe0-94b3-be600a527d27",
   "metadata": {},
   "source": [
    "## Recognizing packages\n",
    "\n",
    "The structure of your directory tree is printed below. You'll be working in the file \"my_script.py\" that you can see in the tree.\n",
    "\n",
    "recognizing_packages\n",
    " MY_PACKAGE\n",
    "    _init_.py\n",
    " package\n",
    "    __init__.py\n",
    " package_py\n",
    "    __init__\n",
    "        __init__.py\n",
    " py_package\n",
    "    __init__.py\n",
    " pyackage\n",
    "    init.py\n",
    " my_script.py\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Use the information from the context to identify the packages in the directory that follow the minimal structure.\n",
    "    import the two packages that follow the minimal package requirements.\n",
    "    Use help() to print information about each imported package.\n",
    "\n",
    "Hint\n",
    "\n",
    "    A minimal package requires a directory containing a single file.\n",
    "    The single file contained in the directory for a minimal package should be named __init__.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28613164-2a6e-4a49-81fa-71f64c323366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local packages\n",
    "import package\n",
    "import py_package\n",
    "\n",
    "# View the help for each package\n",
    "help(package)\n",
    "help(py_package)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65381a-4255-41cf-ac65-071e8aa1eb94",
   "metadata": {},
   "source": [
    "## Adding functionality to packages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great work on those exercises.  You're now a bonafide Python developer.  \n",
    "\n",
    "The next step to package development is to add some useful functionality.  To start, lets again look at the file structure we'll be using.  Here we've added a file to our package's directory named \"utils.py\".  Again, when we import and work with our resulting package we'll be in the \"my_script.py\" file thats in the same directory as our package.  \n",
    "\n",
    "Note that we can choose a different name than \"utils.py\", but keep in mind that file names should follow the same conventionsas package naming.  That is file names should be all lower case and avoid underscores unless it improves readability or if its a special case such as our package's \"__init__.py\" file.  With the right structure in place, the next step is to write some code.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Here, in our \"utils.py\" file, we write a function that prints one of two possible statements based on user input.  Our \"utils.py\" file is known as a submodule and we can import it with a dot notation syntax of the form: \n",
    "# package_name.submodule_name.function_name  (be careful here, check the instances in below code boxes)\n",
    "In this \"my_script.py\" example, we call \"my_packages.utils.we_need_talk\".  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Alternatively, we can use our package's \"__init__.py\" file to make our \"utils.py\" function more easily accessible by the user.  To do this, we import our function in our \"__init__.py\" file as you see below.  The dot notation we use when writing \".utils\" is known as a relative import and it must be used when packaging in Python 3 and above when working under \"work_dir/my_package/__init__.py\".  \n",
    "\n",
    "Importing our function in the \"__init__.py\" file saves some typing when we want to import and use our function.  We're now able to call \"my_packages.we_need_talk.py\" without including the additional reference to our utils submodule, importing the function in the \"__init__.py\" file took care of this reference for us.  \n",
    "\n",
    "In our example, we added a single file, or submodule, to our package, but we can extend this structure indefinitely to meet our needs.  However, when creating larger packages you must be more mindful about organization.  When working with multiple submodules should you import them all in \"__init__.py\"?  As a general rule, you should import your packages' key functionality in your \"__init__.py\" file to make it directly and easily accessible.  \n",
    "\n",
    "Less central functionality can be accessed by user throughthe longer submodule dot syntax we saw earlier.  The decision of what is key functionality is a gray area, and because of this, there isn't always a clear best way to organize your package.  As a package developer, you'll need to use your judgement to decide what you think will give your users the best experience.  \n",
    "\n",
    "In addition to adding additional submodules, you can also build out packages inside your package.  These are know as subpackages.  Notice how the subpackage still follows the packaging rules of being a directory with an \"__init__.py\" file.  We won't covering subpackages in depth in this course but exposure to these different structures can be helpful when lookig at someone else's code.  \n",
    "\n",
    "\n",
    "Alright, we just covered how to add functionality by defining functions in a package by using submodules and the \"\"__init__.py\" file.  In the following exercises, you'll practice this important skill.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "working_directory\n",
    " my_script.py\n",
    " my_package\n",
    "        __init__.py\n",
    "        datacamp.py(s)\n",
    "        utils.py \n",
    "       \n",
    "\n",
    "\n",
    "working_directory\n",
    " my_script.py\n",
    " my_package\n",
    "        __init__.py\n",
    "        datacamp.py(s)\n",
    "        utils.py\n",
    "        sub_package\n",
    "               __init__.py\n",
    "               datacamp.py(s)\n",
    "               utils2.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49795921-f1e9-4af1-866b-e758a1fdc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(py39) jhu@debian:~/.virtual_environments$ mkdir my_packages\n",
    "(py39) jhu@debian:~/.virtual_environments$ cd my_packages/\n",
    "(py39) jhu@debian:~/.virtual_environments/my_packages$ nano __init__.py\n",
    "(py39) jhu@debian:~/.virtual_environments/my_packages$ nano utils.py\n",
    "(py39) jhu@debian:~/.virtual_environments/my_packages$ cd ..\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat my_packages/utils.py \n",
    "def we_need_talk(break_up=False):\n",
    "    \"\"\"Helper for communicating with significant other\"\"\"\n",
    "    if break_up:\n",
    "        print('Its not you, its me...')\n",
    "    else:\n",
    "        print('I <3 U!')\n",
    "(py39) jhu@debian:~/.virtual_environments$ python my_script.py \n",
    "Its not you, its me...\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat my_script.py \n",
    "# Import utils submodule\n",
    "import my_packages.utils  ###########################################################################################\n",
    "\n",
    "\n",
    "# Decide to start seeing other people\n",
    "my_packages.utils.we_need_talk(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat my_script.py \n",
    "......\n",
    "# After we added \"from .utils import we_need_talk\" in the \"__init__.py\" ####\n",
    "# Import custom package\n",
    "import my_packages\n",
    "\n",
    "# Realize you're with your soulmate           # So we don't need to type \"from my_packages.utils import we_need_talk\"\n",
    "my_packages.we_need_talk(False)  ####################################################################################\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat my_packages/__init__.py \n",
    "# This is a init file\n",
    "from  .utils import we_need_talk  ###################################################################################\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ python my_script.py \n",
    "I <3 U!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78926707-7fd9-4a6e-8958-57e6ab9c052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its not you, its me...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from my_packages import utils\n",
    "\n",
    "utils.we_need_talk(break_up=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc389d0-9aa3-431b-ba09-6b47d4daafbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I <3 U!\n"
     ]
    }
   ],
   "source": [
    "from my_packages.utils import we_need_talk\n",
    "\n",
    "we_need_talk(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e127ffd-475b-413a-996d-7e38e88ed096",
   "metadata": {},
   "source": [
    "## Adding functionality to your package\n",
    "\n",
    "Thanks to your work before, you already have a skeleton for your Python package. In this exercise, you will work to define the functions needed for a text analysis of word usage.\n",
    "\n",
    "In the file \"counter_utils.py\", you will write 2 functions to be a part of your package: \"plot_counter\" and \"sum_counters\". The structure of your package can be seen in the tree below. For the coding portions of this exercise, you will be working in the file counter_utils.py.\n",
    "\n",
    "text_analyzer\n",
    " __init__.py\n",
    " counter_utils.py\n",
    "\n",
    "Instructions 1/3\n",
    "35 XP\n",
    "\n",
    "    Question 1\n",
    "#    Define top_items using plot_counter's inputs.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "#    Return the correct output from sum_counters.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    You just wrote two functions for your package in the file counter_utils.py named plot_counter & sum_counters. Which of the following lines would correctly import these functions in __init__.py using relative import syntax?\n",
    "from counter_utils import plot_counter, sum_counters\n",
    "from . import plot_counter, sum_counters\n",
    "# from .counter_utils import plot_counter & sum_counters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8893ccf-b2e7-42c1-9d39-774da171507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'s': 6, 'w': 5, 'c': 4, 'r': 3, 'd': 3, 'y': 2, 'a': 1, 'f': 1, 'g': 1, 'e': 1, 'q': 1})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import needed functionality\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_counter(counter, n_most_common=5):\n",
    "    \n",
    "    # Subset the n_most_common items from the input counter\n",
    "    top_items = counter.most_common(n_most_common)\n",
    "    \n",
    "    # Plot `top_items`\n",
    "    #plot_counter_most_common(top_items)  ###########################################################################\n",
    "    plt.plot(list(counter.keys())[:n_most_common], \n",
    "             list(counter.values())[:n_most_common])  ###############################################################\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def sum_counters(counters):\n",
    "    # Sum the inputted counters\n",
    "    #return sum(counters.values(), Counter())  ### I think its a mistake ############################################\n",
    "    \n",
    "    return sum(counters.values())\n",
    "\n",
    "\n",
    "aa = Counter('ascwcsyswsscsfwwrrgrddewdqyc')\n",
    "print(aa)\n",
    "\n",
    "plot_counter(aa)\n",
    "\n",
    "sum_counters(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d58c4e3-93f7-441f-8e0f-d2e832bd8950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'s': 6, 'w': 5, 'c': 4, 'r': 3, 'd': 3, 'y': 2, 'a': 1, 'f': 1, 'g': 1, 'e': 1, 'q': 1})\n",
      "dict_values([1, 6, 4, 5, 2, 1, 3, 1, 3, 1, 1])\n",
      "[('s', 6), ('w', 5), ('c', 4), ('r', 3), ('d', 3)]\n"
     ]
    }
   ],
   "source": [
    "aa = Counter('ascwcsyswsscsfwwrrgrddewdqyc')\n",
    "print(aa)\n",
    "print(aa.values())\n",
    "\n",
    "bb = aa.most_common(5)\n",
    "print(bb)\n",
    "\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat text_analyzer_script.py \n",
    "# Import needed functionality\n",
    "from text_analyzer import plot_counter, sum_counters\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "word_counts = Counter('ascwcsyswsscsfwwrrgrddewdqyc')\n",
    "\n",
    "# Sum word_counts using \"sum_counters\" from \"text_analyzer\"\n",
    "word_count_totals = sum_counters(word_counts)\n",
    "\n",
    "# Plot word_count_totals using plot_counter from text_analyzer\n",
    "plot_counter(word_counts)\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat text_analyzer/counter_utils.py \n",
    "# Import needed functionality\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_counter(counter, n_most_common=5):\n",
    "    \n",
    "    # Subset the n_most_common items from the input counter\n",
    "    top_items = counter.most_common(n_most_common)\n",
    "    \n",
    "    # Plot `top_items`\n",
    "    plt.plot(list(counter.keys())[:n_most_common], \n",
    "             list(counter.values())[:n_most_common])  ###############################################################\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def sum_counters(counters):\n",
    "    # Sum the inputted counters\n",
    "    return sum(counters.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab2eb2-eb2b-4584-ba07-a3e8530137d5",
   "metadata": {},
   "source": [
    "## Using your package's new functionality\n",
    "\n",
    "You've now created some great functionality for text analysis to your package. In this exercise, you'll leverage your package to analyze some tweets written by DataCamp & DataCamp users.\n",
    "\n",
    "The object \"word_counts\" is loaded into your environment. It contains a list of Counter objects that contain word counts from a sample of DataCamp tweets.\n",
    "\n",
    "The structure you've created can be seen in the tree below. You'll be working in \"my_script.py\".\n",
    "\n",
    "working_dir\n",
    " text_analyzer\n",
    "     __init__.py\n",
    "     counter_utils.py\n",
    " my_script.py\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    import your \"text_analyzer\" at the top of the script.\n",
    "    Use the sum_counters() function from text_analyzer to aggregate all the Counters in word_counts.\n",
    "    Use the plot_counter() function from text_analyzer to visualize the tweet's most used words while tweeting.\n",
    "\n",
    "Hint\n",
    "\n",
    "    To import a package, utilize the syntax import package_name.\n",
    "    Use the correct dot notation to call functions from your package (i.e. package_name.function_name).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70ada1a9-7511-4262-bc31-0e4073520394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# working_dir/my_script.py  -----------------------------------------------------------------------------------------\n",
    "# Import local package\n",
    "from text_analyzer import plot_counter, sum_counters\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "word_counts = Counter('ascwcsyswsscsfwwrrgrddewdqyc')\n",
    "\n",
    "\n",
    "# Sum word_counts using \"sum_counters\" from \"text_analyzer\"\n",
    "word_count_totals = sum_counters(word_counts)\n",
    "print(word_count_totals)\n",
    "\n",
    "# Plot word_count_totals using plot_counter from text_analyzer\n",
    "plot_counter(word_counts)  #word_count_totals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0838c4-3c93-481a-bada-dd4e819a6d5d",
   "metadata": {},
   "source": [
    "## Making your package portable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# **Now that you have a functional package you might want to share it with your colleagues.  The two main steps to sharing a Python package are creating a \"setup.py\" and \"requirements.txt\".  \n",
    "\n",
    "These two pieces provide information on how to install your package and recreate its required environment.  These files list information about what dependancies you've used as well as allowing you to describe with additional metadata.  \n",
    "\n",
    "Here is how two files fit into our package structure.  They're located at the same level as our package directory.  Now lets see what content goes into the files themselves.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# A \"requirements.txt\" file shows how to recreate the environment needed to properly use your package.  \n",
    "This includes a list of Python packages and optionally the version requirements for each package.  Here we see 3 different ways to specify our requirements.  If we don't have a reason to specify a version we can just list the package name as you see here for Matplotlib.  If version is important.  We can mark a specific version by using a double equals, or mark a minimum version by using greater than or equal.  \n",
    "\n",
    "Since open source packages are constantly envolving, apecifying a version can be a big help to your users.  To leverage our requirements file we can use this \"pip install -r requirements.txt\" command.  \n",
    "# *******************************************************************************************************************\n",
    "This installs all the packages listed with respect the correct version.  Note that we didn't actually install our package, we just recreated its environment.  The \"setup.py\" is what tells pip how to install our actual package.  Additionally, its info will be used by PyPi if you decide to publish.  The contents of this in our case contains a single call to the setup function from the setuptools package.  There are other options, but \"setuptools\" is one of the most commom and powerful choices.  Below we use just a few of the possible setup arguments.  There are many more options available that you can read more about in the \"setuptools\" documentation.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "The argument's names make them fairly self-explanatory; for example, your packages' name is assigned to name and so on.  Some less obvious arguments in our example are \"install_requires\" and \"packages\".  \n",
    "\n",
    "The \"packages\" in essence lists the location of all the \"__init__.py\" files in our package.  Our package has a single \"__init__.py\" file and its in the directory \"my_package\".  As we saw before, more complex packages might include subpackages with their own \"__init__.py\" files, if this was the case we would also list their location here.  Until you writing more complex packages, the contents of the packages list will likely be the same as the name argument.  \n",
    "\n",
    "The \"install_requires\" might look familiar, in the case of our package, the contents are the same as our requirements file.  An example of when \"install_requires\" can differ is if you want to specify where pip should download pacakge from.  This can be specified in the \"requirements.txt\" file as shown below.  We won't go into much detail here since this advanced option is not often needed in everyday use.  To read up more on the differences you can see the documentation by Google \"install_requires vs requirements files\".  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Now that we've completed our \"setup.py\", we can install our package with pip using \"pip install .\" from the inside the same directory as our package. ( Think Think \"pip install -r requirements.txt\" command )  This will install our package at an environment level so we can import it into any Python script using the same environment.  \n",
    "\n",
    "We just covered some important aspects of how to make your package portable.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# *******************************************************************************************************************\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "working_dir\n",
    " setup.py\n",
    " requirements.txt\n",
    " my_package\n",
    "      __init__.py\n",
    "      counter_utils.py\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "working_dir/requirements.txt   --------------------------------------------------------------------------------------\n",
    "# Specify where to install requirements from\n",
    "--index-url https://pypi.python.org/simple/\n",
    "\n",
    "\n",
    "# Needed packages/versions\n",
    "matplotlib\n",
    "numpy==1.15.4\n",
    "pycodestyle>=2.4.0\n",
    "\n",
    "\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ pip install -r requirements.txt  -----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "working_dir/setup.py  -----------------------------------------------------------------------------------------------\n",
    "from setuptools import setup\n",
    "\n",
    "setup(name=\"my_packages\", \n",
    "      version=\"0.0.1\", \n",
    "      description=\"An example package for DataCamp\", \n",
    "      author=\"Adam Spannbauer\", \n",
    "      author_email=\"spannbaueradam@gmail.com\", \n",
    "      packages=[\"my_packages\"], \n",
    "      install_requires=[\"matplotlib\", \n",
    "                        \"numpy==1.15.4\", \n",
    "                        \"pycodestyle>=2.4.0\"])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7d249-9659-4056-885e-22b8c8f9eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(py39) jhu@debian:~/.virtual_environments$ cat requirements.txt \n",
    "# working_dir/requirements.txt   --------------------------------------------------------------------------------------\n",
    "# Specify where to install requirements from\n",
    "--index-url https://pypi.python.org/simple/\n",
    "\n",
    "\n",
    "# Needed packages/versions\n",
    "matplotlib\n",
    "numpy\n",
    "pycodestyle\n",
    "\n",
    "token_utils\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat setup.py \n",
    "# working_dir/setup.py  -----------------------------------------------------------------------------------------------\n",
    "from setuptools import setup\n",
    "\n",
    "\n",
    "setup(name=\"text_analyzer\", \n",
    "      version=\"0.0.1\", \n",
    "      description=\"An example package for DataCamp\", \n",
    "      author=\"John HHU\", \n",
    "      author_email=\"john.hhu2020@gmail.com\", \n",
    "      packages=[\"text_analyzer\"], \n",
    "      install_requires=[\"matplotlib\", \n",
    "                        \"numpy==1.15.4\", \n",
    "                        \"pycodestyle>=2.4.0\", \n",
    "                        \"token_utils\"])\n",
    "(py39) jhu@debian:~/.virtual_environments$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342bc8c-5c6e-42ab-8888-611c600d4d58",
   "metadata": {},
   "source": [
    "## Writing requirements.txt\n",
    "\n",
    "We covered how having a \"requirements.txt\" file can help your package be more portable by allowing your users to easily recreate its intended environment. In this exercise, you will be writing the contents of a requirements file to a python variable.\n",
    "\n",
    "Note, in practice, the code you write in this exercise would be written to it's own txt file instead of a variable in your python session.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Write the requirement for \"matplotlib\" with at least version 3.0.0 or above.\n",
    "    Write the requirement for \"numpy\" version 1.15.4 exactly.\n",
    "#    Write the requirement for \"pandas\" with at most version 0.22.0.\n",
    "    Write a non-version specific requirement for \"pycodestyle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8883d-ced8-42f3-b61d-8e967bbe7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = \"\"\"\n",
    "matplotlib>=3.0.0\n",
    "numpy==1.15.4\n",
    "pandas<=0.22.0\n",
    "pycodestyle\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "working_dir/requirements.txt   --------------------------------------------------------------------------------------\n",
    "# Specify where to install requirements from\n",
    "--index-url https://pypi.python.org/simple/\n",
    "\n",
    "\n",
    "# Needed packages/versions\n",
    "matplotlib\n",
    "numpy==1.15.4\n",
    "pycodestyle>=2.4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f815d4-8ae6-47fa-8a32-1ab2f56fb788",
   "metadata": {},
   "source": [
    "## Installing package requirements\n",
    "\n",
    "You've now written a \"requirements.txt\" file to recreate your package's environment using a pip install command. Given that you are running a shell session in the work_dir structure shown below, what command would properly recreate the my_package environment from requirements.txt?\n",
    "\n",
    "work_dir/\n",
    " my_package\n",
    "  __init__.py\n",
    "  utils.py\n",
    " requirements.txt\n",
    " setup.py\n",
    "\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    pip install requirements.txt\n",
    "    press\n",
    "    1\n",
    "    pip install -r requirements\n",
    "    press\n",
    "    2\n",
    "    pip install -r setup.py\n",
    "    press\n",
    "    3\n",
    "#    pip install -r requirements.txt\n",
    "    press\n",
    "    4\n",
    "    \n",
    "Hint\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "    The structure for pip installing a requirements file is the following: \n",
    "#    \"pip install -r requirements_file_name\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4f205-b73a-4b69-b876-bf08450e8921",
   "metadata": {},
   "source": [
    "## Creating setup.py\n",
    "\n",
    "# In order to make your package installable by pip you need to create a \"setup.py\" file. \n",
    "In this exercise you will create this file for the \"text_analyzer\" package you've been building.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    import the needed function, setup, from the \"setuptools\" package.\n",
    "    Complete the name & packages arguments; keep in mind your package is located in a directory named text_analyzer.\n",
    "    List yourself as the author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5494e38-2c26-473e-915f-bc0fd976ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed function from setuptools\n",
    "from setuptools import setup\n",
    "\n",
    "# Create proper setup to be used by pip\n",
    "setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='johnhhu',\n",
    "      packages=['collections', 'matplotlib'])  ######################################################################\n",
    "\n",
    "\n",
    "# Import needed function from setuptools\n",
    "from setuptools import setup\n",
    "\n",
    "# Create proper setup to be used by pip\n",
    "setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='username',\n",
    "      packages=['text_analyzer'])\n",
    "\n",
    "\n",
    "\n",
    "working_dir/setup.py  -----------------------------------------------------------------------------------------------\n",
    "from setuptools import setup\n",
    "\n",
    "setup(name=\"my_packages\", \n",
    "      version=\"0.0.1\", \n",
    "      description=\"An example package for DataCamp\", \n",
    "      author=\"Adam Spannbauer\", \n",
    "      author_email=\"spannbaueradam@gmail.com\", \n",
    "      packages=[\"my_packages\"],  ####################################################################################\n",
    "      install_requires=[\"matplotlib\", \n",
    "                        \"numpy==1.15.4\", \n",
    "                        \"pycodestyle>=2.4.0\"])\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b7d68-f050-4ada-89eb-0bf829630f05",
   "metadata": {},
   "source": [
    "## Listing requirements in setup.py\n",
    "\n",
    "We created a \"setup.py\" file earlier, but we forgot to list our dependency on \"matplotlib\" in the \"install_requires\" argument. In this exercise you will practice listing your version specific dependencies by correcting the setup.py you previously wrote for your text_analyzer package.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    import the needed function, setup, from the setuptools package.\n",
    "    List yourself as the author.\n",
    "    Specify your install_requires to require matplotlib version 3.0.0 or above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371b5e9-bd93-4228-9942-b3635c3b1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir/setup.py  -----------------------------------------------------------------------------------------------\n",
    "# Import needed function from \"setuptools\"\n",
    "from setuptools import setup\n",
    "\n",
    "# Create proper setup to be used by pip\n",
    "setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='____',\n",
    "      packages=['text_analyzer'],\n",
    "      install_requires=['matplotlib'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab4bb4f-db02-4492-84d2-4841e5588de4",
   "metadata": {},
   "source": [
    "## Adding classes to a package\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "**So far you've been able to create a fully portable Python package, and you even added functionality to your package by utilizing functions.  We'll now look at how you can use classes to strengthen your packages's functionality.  \n",
    "\n",
    "Object Oriented Programming, or OOP, is a great way to write modular code, and reap the benefits of modularity as easily understood and extensible code.  We'll cover some aspectof OOP, but if you want a deeper dive I recommend the dedicated DataCamp courses.  \n",
    "\n",
    "\n",
    "Lets jump into some code.  \n",
    "# *******************************************************************************************************************\n",
    "In Python, OOP can be utilized by writing classes.  Here we see a minimal class implementation.  To start we use the keyword class followed by the name of our class.  According to PEP 8, our class name should be written in camel case, that is, our class name should start with a capital letter and every word in the name should have a capital letter as well.  Unlike function and package names, class names should never contain underscores.  \n",
    "\n",
    "Next, is some documentation that will appear when a user calls help on our class.  We'll cover the details of this particular documentation formatting later in the course.  \n",
    "\n",
    "Last, we see a function with a familiar name __init__().  Similarly to your package's \"__init__.py\" file, this will initialize everything when a user wants to leverage your class.  You might have noticed we use a variable named \"self\", we'll get back to this in a couple slides.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "To make our class easily accessible, we can add it to our \"__init__.py\" file just like we've done with functions before.  We use relative import syntax to import MyClass from the \"my_class.py\" file in the same directory, we can now import the package and access MyClass easily.  \n",
    "\n",
    "Now lets create what's known as an instance of MyClass.  To do this, we call MyClass like a function and supply a string to the value parameter.  Calling our class like this tells Python that we want to create an instance of our class by using the init method.  Recall that MyClass's init method set the contents of value to a variable we referenced as \"self.attribute\".  Users can access this attribute by referencing \"my_instance.attribute\".  Note, nowhere in this script do we see the self-object what we used when defining our class.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Lets look more in depth at the use of self in our class's init method.  \n",
    "# The \"self\" is, in essence, a way to refer to a class instance even though we don't know what the user is actually going to name their instance.  ( Then what about the self arg in def under class? an instance of that function ? )\n",
    "\n",
    "When defining typical class instance method, like __init__, self is the first argument.  However, if you recall creating an instance of MyClass, when using __init__, the user doesn't need to pass a value to this self argument; this is done automatically behind the scenses. Once in the method body, we can use self to access or define attributes.  The usercan then access these attributes by using their class instance's name in place of self, like we did in our script.  Technically we can use a different word than self, but this is a very strong PEP8 convention and not abiding by it will make your code very hard to read by your collaborators.  \n",
    "\n",
    "\n",
    "We've covered how to add a minimal calss to our package and leverage its functionaity by importing our package.  Additionally, we touched on the role of the self convention in writing classes.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586ede3-b6bc-4fba-a3a2-b479df8d5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a minimal class with an attribute\n",
    "class MyClass():\n",
    "    \"\"\"A minimal example class\n",
    "    \n",
    "    :param value: value to set as the ''attribute'' attribute\n",
    "    :ivar attribute: contains the contents of ''value'' passed in init\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, value):\n",
    "        # Define attribute with the contents of the value param\n",
    "        self.attribute = value\n",
    "\n",
    "\n",
    "\n",
    "work_dir/my_package/__init__.py  ------------------------------------------------------------------------------------\n",
    "\n",
    "from .my_class import MyClass \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import my_package\n",
    "\n",
    "# Create instance of MyClass\n",
    "my_instance = my_package.MyClass(value='class attributevalue')\n",
    "\n",
    "# Print out class attribute value\n",
    "print(my_instance.attribute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13352c-15ff-40d3-a97c-3ecfb4d2d940",
   "metadata": {},
   "source": [
    "## Writing a class for your package\n",
    "\n",
    "We've covered how classes can be written in Python. In this exercise, you'll be creating the beginnings of a Document class that will be a foundation for text analysis in your package. Once the class is written you will modify your package's __init__.py file to make it easily accessible by your users.\n",
    "\n",
    "Below is the structure of where you'll be working.\n",
    "\n",
    "working_dir\n",
    " text_analyzer\n",
    "     __init__.py\n",
    "     counter_utils.py\n",
    "     document.py\n",
    " my_script.py\n",
    "\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "\n",
    "    Question 1\n",
    "    You are working in \"document.py\".\n",
    "    Finish the def statement that will create a new Document instance when a user calls \"Document()\".\n",
    "    Use your knowledge of PEP 8 conventions to complete the definition of the newly named class method.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    You just wrote the beginnings of a Document class that you'll build upon to perform text analysis. In this exercise, you'll test out its current functionality of storing text.\n",
    "    Below is the document tree that you've built up so far when developing your package. You'll be working in my_script.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362502a-8667-4c3b-bdb1-be1342a3fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "\n",
    "\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = text_analyzer.Document(text=datacamp_tweet)\n",
    "\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7b1fc-5fed-46df-9ea0-8de525490ebc",
   "metadata": {},
   "source": [
    "## Using your package's class\n",
    "\n",
    "You just wrote the beginnings of a Document class that you'll build upon to perform text analysis. In this exercise, you'll test out its current functionality of storing text.\n",
    "\n",
    "Below is the document tree that you've built up so far when developing your package. You'll be working in my_script.py.\n",
    "\n",
    "working_dir\n",
    " text_analyzer\n",
    "     __init__.py\n",
    "     counter_utils.py\n",
    "     document.py\n",
    " my_script.py\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    import your \"text_analyzer\" package.\n",
    "    Create an instance of Document with the \"datacamp_tweet\" variable that's been loaded into your session.\n",
    "    Print the contents of the text attribute of your newly created Document instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09388498-4191-48f3-b8b4-6ce398821e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_analyzer import Document\n",
    "\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "import ____\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = text_analyzer.Document(text=datacamp_tweet)\n",
    "\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "from text_analyzer import Document\n",
    "\n",
    "\n",
    "datacamp_tweet = 'Hello, this is a sampe Tweet from DataCamp account'\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = Document(text=datacamp_tweet)\n",
    "\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document.text)\n",
    "\n",
    "(py39) jhu@debian:~/.virtual_environments$ cat text_analyzer/document.py \n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "(py39) jhu@debian:~/.virtual_environments$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f56630-9778-4210-9d62-49390092eb18",
   "metadata": {},
   "source": [
    "## Adding functionality to classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "**In our last lesson, we created a Document class that currently only serve as a container for our text.  \n",
    "\n",
    "Lets look at our current definition of Document and talk about how we can improve its functionality.  Right now the class is just a container for the user provided text; this doesn't add much value for our user.  \n",
    "\n",
    "# In order for our Document class to be more useful, we can add more attributes & methods besides __init__.  \n",
    "# *******************************************************************************************************************\n",
    "For example, lets say that in our workflow we always want to tokenize our documents as a first step.  \"Tokenization\" is a common step in text analysis, it is the process of breaking up a document into individual words, also known as \"tokens\".  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "As we've learned, __init__ is whats called when a user wants to create an instance of Document.  This would be a convenient location to put a tokenization step.  \n",
    "# Place the tokenization process inside of __init__ will ensure our Document is tokenized as soon as it is created, \n",
    "and this will save your user's the trouble of thinking about this step.  Our new __init__ method might look like this.  You can see that we added a line that calls \"self._tokenize()\"_ and dumps the output innto an attribute named tokens.  So where does \"_tokenize\"_ come from?  and why does it have an underscore in fron of it?  \n",
    "# *******************************************************************************************************************\n",
    "Lets first answer the question of where the method came from.  Since this course isn't focused on teaching text analytics, we aren't going to cover the tokenization function implementation; we'll simply import a function to do it for us.  In a way, this demontrates the beauty of modularity and Python's community.  Often times there are functions already written by someone in the community, and all you need to do is find out where they are and import them for your own use cases.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Moving on to the definition of \"_tokenize\"_.  We only pass one parameter to the function, the prescribed self convention that will represent an instance of the Document object.  Since the tokenize function is already written, all that's left to do is call it on the text attribute.  And viola.  (Think here)  To tokenization process will now be completed automatically as soon as a user creates a Document instance.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "So why did we use a leading \"_ \" when naming \"_tokenize\"_?  The reason we added the tokenization process to the __init__ method is that we wanted tokenization to happen immediately without the user having to think about it.  Because of this, the user doesn't need to call \"_tokenize\"_ themselves; in other words, this method doesn't need to be \"public\" to the user.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "According to PEP8, non-public methods should be named with a single underscore \"_ \".  This signifies to the user that the method is intended for internal use only.  Users can still use non-public methods in their own workflow, but they must do so at their own risk since the developer did not intend for them to do so.  \n",
    "\n",
    "The risks of using non-public method in your own workflow include: little or no documentation and function's input or output might change without warning when the develpoer updates their package.  \n",
    "\n",
    "\n",
    "\n",
    "You've now seen how we can add more functionality to our Document class.  In the upcoming exercises, you'll add additional methods to streamline our text analytics workflow; you'll even write your first non-public method.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d67d5642-dccd-4dbe-bd67-7e18c54e38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.tokens = self._tokenize()\n",
    "        \n",
    "        \n",
    "        \n",
    "doc = Document('test doc')\n",
    "doc.text\n",
    "doc.tokens\n",
    "\n",
    "\n",
    "                                            otherwise we need to write as \"from token_utils import tokenize\"\n",
    "                                            ---------------------------------------------------------------------\n",
    "# Import function to perform tokenization  (yes, if we put the \"token_utils.py\" under our \"text_analyzer\" package)\n",
    "from .token_utils import tokenize   #################################################################################\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "def Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by 'text' parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        self.tokens = self._tokenize()\n",
    "        \n",
    "    def _tokenize(self):  ###########################################################################################\n",
    "        return tokenize(self.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaadac-6bb1-4077-a2ef-c751ed879f23",
   "metadata": {},
   "source": [
    "## Writing a non-public method\n",
    "\n",
    "In the lesson, we covered how to add functionality to classes using non-public methods. By defining methods as non-public you're signifying to the user that the method is only to be used inside the package.\n",
    "\n",
    "In this exercise, you will define a non-public method that will be leveraged by your class to count words.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "#    \"Counter\" from \"collections\" has been loaded into your environment, as well as the function \"tokenize()\".\n",
    "#    Add a method named \"count_words\" as a non-public method.\n",
    "#    Give your non-public method the functionality to count the contents tokens attribute using Counter().\n",
    "#    Utilize your new function in the __init__ method.\n",
    "\n",
    "Hint\n",
    "\n",
    "#    Your new method should be named \"_count_words\". Note the leading underscore that denotes it as a non-public method.\n",
    "#    To count the tokens attribute you'll need to pass \"tokens\" to \"Counter()\" using the \"self.attribute\" syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b277c-aaa1-493c-8d8d-191da5d4149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        # Tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Perform word count with non-public count_words method\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        return tokenize(self.text)\n",
    "\t    \n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        return Counter(self.tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53889c95-b6b3-4a1e-b751-3cf191644a60",
   "metadata": {},
   "source": [
    "## Using your class's functionality\n",
    "\n",
    "You've now added additional functionality to your Document class's __init__ method that automatically processes text for your users. In this exercise, you'll act as one of those users to see the benefits of your hard work.\n",
    "\n",
    "The Document class (copied below) has been loaded into your environment (complete with your new updates).\n",
    "\n",
    "class Document:\n",
    "  def __init__(self, text):\n",
    "    self.text = text\n",
    "    # pre tokenize the document with non-public tokenize method\n",
    "    self.tokens = self._tokenize()\n",
    "    # pre tokenize the document with non-public count_words\n",
    "    self.word_counts = self._count_words()\n",
    "\n",
    "  def _tokenize(self):\n",
    "    return tokenize(self.text)\n",
    "\n",
    "  # non-public method to tally document's word counts with Counter\n",
    "  def _count_words(self):\n",
    "    return Counter(self.tokens)\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Create a new \"Document\" instance from the datacamp_tweets data set loaded into your environment. The datacamp_tweets object is a single string containing hundreds of tweets written by DataCamp & DataCamp users.\n",
    "    Print the first 5 tokens from datacamp_doc.\n",
    "    Print the top 5 most common words that were calculated by the non-public _count_words() method automatically in the Document.__init__ method.\n",
    "\n",
    "Hint\n",
    "\n",
    "    To create an instance of a class, call it like a function with the appropriate arguments.\n",
    "    View the class definition to see which attribute of Document contains the tokens.\n",
    "    View the class definition to see which attribute of Document contains word counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc453fac-ed63-4906-8aae-bc34c8b775b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ python text_analyzer_script.py \n",
    "28\n",
    "/home/jhu/datacmap_data_engineering/text_analyzer/counter_utils.py:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
    "  plt.show(block=True)\n",
    "Hello, this is a sampe Tweet from DataCamp account\n",
    "[type=1 (NAME)  string='Hello'  start=(1, 0)  end=(1, 5)  line='Hello, this is a sampe Tweet from DataCamp account', type=54 (OP)  string=','  start=(1, 5)  end=(1, 6)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='this'  start=(1, 7)  end=(1, 11)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='is'  start=(1, 12)  end=(1, 14)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='a'  start=(1, 15)  end=(1, 16)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='sampe'  start=(1, 17)  end=(1, 22)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='Tweet'  start=(1, 23)  end=(1, 28)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='from'  start=(1, 29)  end=(1, 33)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='DataCamp'  start=(1, 34)  end=(1, 42)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='account'  start=(1, 43)  end=(1, 50)  line='Hello, this is a sampe Tweet from DataCamp account', type=4 (NEWLINE)  string=''  start=(1, 50)  end=(1, 51)  line='', type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line='']\n",
    "Counter({'': 2, 'Hello': 1, ',': 1, 'this': 1, 'is': 1, 'a': 1, 'sampe': 1, 'Tweet': 1, 'from': 1, 'DataCamp': 1, 'account': 1})\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/document.py \n",
    "# Import function to perform tokenization\n",
    "#####from .token_utils import tokenize\n",
    "from token_utils import tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        return tokenize(self.text)\n",
    "\n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        return Counter([i.string for i in self.tokens])  ############################################################\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ \n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ python text_analyzer_script.py \n",
    "28\n",
    "/home/jhu/datacmap_data_engineering/text_analyzer/counter_utils.py:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
    "  plt.show(block=True)\n",
    "Hello, this is a sampe Tweet from DataCamp account\n",
    "[type=1 (NAME)  string='Hello'  start=(1, 0)  end=(1, 5)  line='Hello, this is a sampe Tweet from DataCamp account', type=54 (OP)  string=','  start=(1, 5)  end=(1, 6)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='this'  start=(1, 7)  end=(1, 11)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='is'  start=(1, 12)  end=(1, 14)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='a'  start=(1, 15)  end=(1, 16)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='sampe'  start=(1, 17)  end=(1, 22)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='Tweet'  start=(1, 23)  end=(1, 28)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='from'  start=(1, 29)  end=(1, 33)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='DataCamp'  start=(1, 34)  end=(1, 42)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='account'  start=(1, 43)  end=(1, 50)  line='Hello, this is a sampe Tweet from DataCamp account', type=4 (NEWLINE)  string=''  start=(1, 50)  end=(1, 51)  line='', type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line='']\n",
    "Counter({'': 2, 'Hello': 1, ',': 1, 'this': 1, 'is': 1, 'a': 1, 'sampe': 1, 'Tweet': 1, 'from': 1, 'DataCamp': 1, 'account': 1})\n",
    "[type=1 (NAME)  string='Hello'  start=(1, 0)  end=(1, 5)  line='Hello, this is a sampe Tweet from DataCamp account', type=54 (OP)  string=','  start=(1, 5)  end=(1, 6)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='this'  start=(1, 7)  end=(1, 11)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='is'  start=(1, 12)  end=(1, 14)  line='Hello, this is a sampe Tweet from DataCamp account', type=1 (NAME)  string='a'  start=(1, 15)  end=(1, 16)  line='Hello, this is a sampe Tweet from DataCamp account']\n",
    "[('', 2), ('Hello', 1), (',', 1), ('this', 1), ('is', 1)]\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer_script.py \n",
    "# Import needed functionality\n",
    "from text_analyzer import plot_counter, sum_counters\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "word_counts = Counter('ascwcsyswsscsfwwrrgrddewdqyc')\n",
    "\n",
    "# Sum word_counts using \"sum_counters\" from \"text_analyzer\"\n",
    "word_count_totals = sum_counters(word_counts)\n",
    "\n",
    "# Plot word_count_totals using plot_counter from text_analyzer\n",
    "#plot_counter(word_count_totals)\n",
    "plot_counter(word_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "from text_analyzer import Document  # thanks for \"from .document import Document\" in \"__init__\", no need to packag.module.class\n",
    "\n",
    "\n",
    "datacamp_tweet = 'Hello, this is a sampe Tweet from DataCamp account'\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = Document(text=datacamp_tweet)\n",
    "\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document.text)\n",
    "\n",
    "\n",
    "print(my_document.tokens)\n",
    "\n",
    "\n",
    "print(my_document.word_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a new document instance from datacamp_tweets\n",
    "datacamp_doc = Document(datacamp_tweet)\n",
    "\n",
    "# print the first 5 tokens from datacamp_doc\n",
    "print(datacamp_doc.tokens[:5])\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "print(datacamp_doc.word_counts.most_common(5))\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50c750-e451-4ed2-93f6-de04585066b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new document instance from datacamp_tweets\n",
    "datacamp_doc = Document(datacamp_tweets)\n",
    "\n",
    "# print the first 5 tokens from datacamp_doc\n",
    "print(datacamp_doc.tokens[:5])\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "print(datacamp_doc.tokens.most_common(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458e08e-f2d3-4afa-a512-a7384d30cdbe",
   "metadata": {},
   "source": [
    "## Classes and the DRY principle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Interesting work on the exercises, our package now has a handy Document class that can be used to analyze any generic text.  What if we wanted to specialize this functionality to focus on the social media data we've been analyzing?  To do this lets create a \"SocialMedia\" class that performs the same functions as the Document class, but can additionally analyze social media specific things like hashtags.  \n",
    "\n",
    "# However, when making this \"SocialMedia\" class we want to preserve the \"Document\" class as is to be used for more general analysis.  SO how can we do this? \n",
    "\n",
    "\n",
    "A first guess might be to copy-paste the contents of the Document class.  This violates what is know as the DRY principle in Software Engineering.  The DRY principle is a great rule that , if followed, can help you write modular, readable code.  DRY stands for: Don't Repeat Yourself.  \n",
    "\n",
    "There are many ways to follow this rule such as writing re-usable functions, classes, and packages.  The benefits of staying DRY are not only saving time by reusing code, but also if you copy-paste code, and later find a bug, you have to remember everywhere you've pasted the buggy code and fix each instance individually.  If you stay DRY you only need to fix the bug once.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "In the case of extending the Document class to be a SocialMedia class,  we can stay DRY by using Object Oriented Programming concept of inheritance.  \n",
    "# With inheritance, we start with a parent class and we pass on its functionality to a child class.  The child class inherits all the methods and attributes of its parent, and we're able to add additional functionality without affecting the parent class.  \n",
    "\n",
    "So how do we leverage inheritance in Python?  To start lets see how the child SocialMedia class fits into the package structure.  It will live as a single file named after the SocialMedia class at the same level as the rest of the package's code.  Now lets see how to actually write a child class that uses inheritance.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "You'll be writing the code for the SocialMedia class, so we'll stick to a generic example.  First, we import the ParentClass for use in defining our ChildClass.  To let Python know we're using inheritance, we pass the ParentClass as an argument in our class statement.  Last, we call our ParentClass's __init__ method.  Remember, __init__ builds an instance of a class and it also accepts self as its first argument.  With this call, we're building an instance of ParentClass and storing it right back into self.  This means that self now has all the metods and attributes that an instance of ParentClass would.  We can now use self as normal to build in additional functionality unique to ChildClass.  Below we just add an attribute.  \n",
    "# *******************************************************************************************************************\n",
    "\n",
    "\n",
    "With our definitions, we can now create an instance of our new ChildClass as we've seen before, and them access attribute from both the parent and the child.  \n",
    "\n",
    "\n",
    "\n",
    "Using inheritance like this can lead to short, easy to read definitions of children classes that are just jam-packed with the functionality of their parents.  We've just covered the important concepts of DRY and class inheritance.  You'lll now use both of these concepts by building a custom SocialMedia class that extends the Document class you've already written.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "working_dir\n",
    " setup.py\n",
    " requirements.txt\n",
    " text_analyzer\n",
    "     __init__.py\n",
    "     counter_utils.py\n",
    "     document.py\n",
    "     tweet.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3dae9-c60c-4dda-a797-3914d5642d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ParentClass object\n",
    "from .parent_class import ParentClass\n",
    "\n",
    "\n",
    "# Create a child class with inheritance\n",
    "class ChildClass(ParentClass):\n",
    "    def __init__(self):\n",
    "        # Call parent's __init__ method\n",
    "        ParentClass.__init__(self)\n",
    "        # Add attribute unique to child class\n",
    "        self.child_attribute = \"I'm a child class attribute\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8797e-16fc-4c84-9fcf-2580cfd579a9",
   "metadata": {},
   "source": [
    "## Using inheritance to create a class\n",
    "\n",
    "You've previously written a \"Document\" class for text analysis, but your NLP project will now have a focus on Social Media data. Your general Document class might be useful later so it's best not destroy it while your focus shifts to tweets.\n",
    "\n",
    "Instead of copy-pasting the already written functionality, you will use the principles of 'DRY' and inheritance to quickly create your new SocialMedia class.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Document has been preloaded in the session.\n",
    "    Complete the class statement to create a SocialMedia class that inherits from Document.\n",
    "    Define SocialMedia's __init__() method that initializes a Document.\n",
    "\n",
    "Hint\n",
    "\n",
    "    To utilize inheritance in a class statement the definition syntax is Child(Parent).\n",
    "    The use of the Document class's __init__() method will allow you to properly inherit its functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c25ecd-de58-4751-b6ff-02c36d070ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)  \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb221ca-d1f6-4515-84c5-da7b1b05f6df",
   "metadata": {},
   "source": [
    "## Adding functionality to a child class\n",
    "\n",
    "You've just written a SocialMedia class that inherits functionality from Document. As of now, the SocialMedia class doesn't have any functionality different from Document. In this exercise, you will build features into SocialMedia to specialize it for use with Social Media data.\n",
    "\n",
    "For reference, the definition of Document can be seen below.\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "class Document:\n",
    "    # Initialize a new Document instance\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        # Pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        return tokenize(self.text)\n",
    "\n",
    "    # Non-public method to tally document's word counts\n",
    "    def _count_words(self):\n",
    "        # Use collections.Counter to count the document's tokens\n",
    "        return Counter(self.tokens)\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "\n",
    "    Question 1\n",
    "    The function \"filter_word_counts()\" has been loaded in your session. Use help() to see its proper usage.\n",
    "    Finish the \"_count_hashtags\" method using \"filter_word_counts()\" so that only words_counts starting with # remain.\n",
    "    \n",
    "Hint\n",
    "\n",
    "    The \"word_counts\" attribute from the Document class is now available on the self object thanks to inheritance.\n",
    "    The call to \"filter_word_counts()\" here will look almost identical to the one you see in help(filter_word_counts).\n",
    "\n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Fill in the first line ofSocialMedia's __init__ method using the parent class to properly utilize inheritance.\n",
    "    Properly call the _count_mentions method in __init__ to add a new feature to SocialMedia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69daac66-b2f4-4832-a702-b28b98c19d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    # Initialize a new Document instance\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        # Pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        return tokenize(self.text)\n",
    "\n",
    "    # Non-public method to tally document's word counts\n",
    "    def _count_words(self):\n",
    "        # Use collections.Counter to count the document's tokens\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        \n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(\"#\")\n",
    "\n",
    "        return filter_word_counts(self.word_counts, first_char='#')  ################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15e8994b-ebcc-47fc-aa0f-e60b7b12211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Hello\n",
      "Bonjour\n",
      "#Tweet\n",
      "hashtags\n",
      "#Sawa\n",
      "Japan\n",
      "#Manga\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self.word_counts attribute: \n",
    "# Counter({'': 2, 'Hello': 1, ',': 1, 'this': 1, 'is': 1, 'a': 1, 'sampe': 1, 'Tweet': 1, 'from': 1, 'DataCamp': 1, 'account': 1})\n",
    "\n",
    "\n",
    "def filter_word_counts(word_count, first_char):\n",
    "    num = 0\n",
    "    for i in word_count:\n",
    "        print(i)\n",
    "        if i[0] == first_char:\n",
    "            num += 1\n",
    "    return num\n",
    "    \n",
    "\n",
    "\n",
    "text = ['#Hello', 'Bonjour', '#Tweet', 'hashtags', '#Sawa', 'Japan', '#Manga']\n",
    "\n",
    "filter_word_counts(text, '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d6ef46cc-3e9f-4a80-9768-34ba6be0bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "dic = {'#': 2, 'Hello': 1, ',': 1, '#this': 1, 'is': 1, 'a': 1, 'sampe': 1, 'Tweet': 1, 'from': 1, 'DataCamp': 1, 'account': 1}\n",
    "\n",
    "type(dic)\n",
    "dic.keys()\n",
    "\n",
    "num = 0\n",
    "for i,j in dic.items():\n",
    "    if i[0] == '#':\n",
    "        num += j\n",
    "        \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6105ccb1-a877-490f-a972-5459127c41eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Document:\n",
    "    # Initialize a new Document instance\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        # Pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        #return tokenize(self.text)  ################################################################################\n",
    "        return self.text.split()\n",
    "\n",
    "    # Non-public method to tally document's word counts\n",
    "    def _count_words(self):\n",
    "        # Use collections.Counter to count the document's tokens\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "\n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='#')      \n",
    "\n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "\n",
    "\n",
    "#tweets_data = []\n",
    "words = list()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        text = tweet['text']\n",
    "        words.extend(text.split())\n",
    "        #tweets_data.append(tweet['text'].split())\n",
    "\n",
    "print(len(words))\n",
    "\n",
    "hashtag_count = 0\n",
    "for i in words:\n",
    "    if i[0] == \"#\":\n",
    "        hashtag_count += 1\n",
    "print(hashtag_count)\n",
    "\n",
    "\n",
    "# But our token_utils.tokenize only read str, so have to do it one tweet by another, or we can do some fix to do it \n",
    "# in a list of tweets or even make it process chunk by chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191be36b-aa10-4096-9ee6-c34f5db083f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ python text_analyzer_script.py \n",
    "......\n",
    "[('RT', 66), ('Trump', 37), ('the', 25), ('for', 25), ('to', 20), ('of', 20), ('a', 17), ('is', 15), ('Donald', 11), ('in', 10), ('Cruz', 9), ('#Trump', 9), ('and', 9), ('@realDonaldTrump', 9), ('The', 8), ('I', 8), ('but', 8), ('by', 8), ('you', 8), ('from', 7), ('she', 7), ('have', 7), ('he', 7), ('just', 7), ('Trump.', 7), ('with', 7), ('was', 7), ('https:/', 6), ('an', 6), ('trump', 6), ('his', 6), ('time', 6), ('https', 6), ('this', 6), ('at', 6)]\n",
    "47\n",
    "128\n",
    "\n",
    "\n",
    "tweets_data = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        tweets_data = tweets_data + ' ' + str(tweet['text'])  ###############################################################\n",
    "\n",
    "        tweet_data = tweet['text']  #########################################################################################\n",
    "\n",
    "\n",
    "tweets = SocialMedia(tweets_data)\n",
    "\n",
    "print(tweets.hashtag_counts)\n",
    "print(tweets.mention_counts)\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/socialmedia.py \n",
    "from text_analyzer import Document\n",
    "\n",
    "\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "\n",
    "\n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='#')  ################################################\n",
    "\n",
    "\n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "def filter_word_counts(word_count, first_char):\n",
    "    num = 0                                        ##### Bad approach, WARNING WARNING\n",
    "    for i, j in word_count.items():\n",
    "        if first_char in i:  ########################################################################################\n",
    "            num += j\n",
    "    return num\n",
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/document.py \n",
    "# Import function to perform tokenization\n",
    "#####from .token_utils import tokenize\n",
    "from token_utils import tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        #return tokenize(self.text)\n",
    "        return self.text.split()  ###########################################################################################\n",
    "\n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        #return Counter([i.string for i in self.tokens])\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "    def plot_counter(self, n_most_common=5):\n",
    "        # Subset the n_most_common items from the input counter\n",
    "        self.top_items = self.most_common(n_most_common)\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot([i[0] for i in self.top_items],\n",
    "                 [i[1] for i in self.top_items])  ############################################################################\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def filter_word_counts(self, first_char):\n",
    "        \"\"\"Pass in a Counter object, filter with 'first_char'\"\"\"\n",
    "        return Counter({ k: v for k, v in self.items() if first_char in k})  ####################################\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "# Recall how I made it in '/home/jhu/datacmap_data_engineering' environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bd7ae668-3bb7-4b56-96e6-284fda58a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " RT @bpolitics: .@krollbondrating's Christopher Whalen says Clinton is the weakest Dem candidate in 50 years https://t.co/pLk7rvoRSn https:/ RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3 Njihuni me Zonjn Trump !!! | Ekskluzive https://t.co/4KmsQi47VD Your an idiot she shouldn't have tried to grab trump after the fact she's an idiot https://t.co/lpASyeNVpG RT @AlanLohner: The anti-American D.C. elites despise Trump for his Ame\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "tweets_data = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        #print(tweet['text'])\n",
    "        #print('\\n')\n",
    "        tweets_data = tweets_data + ' ' + tweet['text']\n",
    "        \n",
    "        \n",
    "print(type(tweets_data))\n",
    "print(tweets_data[:500])\n",
    "\n",
    "\n",
    "# Need to try it on my Colab env and my own Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82979ac8-bc8f-4027-98c1-81f3b468f50c",
   "metadata": {},
   "source": [
    "## Using your child class\n",
    "\n",
    "Thanks to the power of inheritance you were able to create a feature-rich, SocialMedia class based on its parent, Document. Let's see some of these features in action.\n",
    "\n",
    "Below is the full definition of SocialMedia for reference. Additionally, SocialMedia has been added to __init__.py for ease of use.\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "\n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='#')      \n",
    "\n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='@')\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    import your text_analyzer custom package.\n",
    "    Define dc_tweets as an instance of SocialMedia with the preloaded datacamp_tweets object as the text.\n",
    "    print the 5 most_common mentioned users in the data using the appropriate dc_tweets attribute.\n",
    "    Use text_analyzer's \"plot_counter()\" method to plot the most used hashtags in the data using the appropriate \"dc_tweets\" attribute.\n",
    "\n",
    "Hint\n",
    "\n",
    "    To create dc_tweets call text_analyzer.SocialMedia.\n",
    "    Reference the definition of SocialMedia to see which attribute of dc_tweets mention counts are stored in.\n",
    "    Reference the definition of SocialMedia to see which attribute of dc_tweets hashtag counts are stored in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57aec7-73cc-469f-8262-c0bb191eae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom text_analyzer package\n",
    "import Document, SocialMedia\n",
    "\n",
    "# Create a SocialMedia instance with datacamp_tweets\n",
    "dc_tweets = SocialMedia(text=datacamp_tweets)\n",
    "\n",
    "# Print the top five most most mentioned users\n",
    "print(dc_tweets.word_counts.most_common(5))\n",
    "\n",
    "# Plot the most used hashtags\n",
    "text_analyzer.plot_counter(dc_tweets.hashtag_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3c2ba-35e7-492f-ac6b-879e532143b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Create a SocialMedia instance with datacamp_tweets\n",
    "dc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)\n",
    "\n",
    "# Print the top five most most mentioned users\n",
    "print(dc_tweets.mention_counts.most_common(5))\n",
    "\n",
    "# Plot the most used hashtags\n",
    "text_analyzer.plot_counter(dc_tweets.hashtag_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d67b8-500a-4745-a7ad-eeae78dc76a1",
   "metadata": {},
   "source": [
    "## Multilevel inheritance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on creating the SocialMedia class for your package.  Thanks to the Document class and inheritance you were able to quickly build up the class for a more specific task, but what if we wanted to go even more specific.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "The SocialMedia class has some general functionality dealing with hashtags and mentions that works across multiple social media platforms.  If we want to include functionality about retweets, it wouldn't be appropriate to include in the general class: instead, we can create a Tweet class.  So how can we do this without losing the benefits of both the Document and SocialMedia classes?  With inheritance again of course.  \n",
    "\n",
    "We've seen before that a child class can inherit from a parent class.  We can continue the family tree again with inheritance.  With multilevel inheritance, our child is all grown up and can pass its functionality onto its children.  Thanks to inheritance we pass along the trace of all prior classes in the family tree.  Note, that in the graphic (slide) we only have one inheriting class at each level, but we are by no means limitd to this.  \n",
    "# Multiple classes can inherit from the same parent.  In fact, one child class can inherit from multiple parents. \n",
    "This more advanced OOP concept is known as \"Multiple Inheritance\".  We won't covering it in this course, but its good to familiarize yourself with the definition in case you hear of it out in the wild.  \n",
    "\n",
    "\n",
    "Lets code up an example of multilevel inheritance.  We'll start with inheritance pattern we've seen before.  Below we define a Parent and Child class that inherits from the Parent.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# We could do this differently, by using the \"super()\" function.  Instead of directly calling the __init__ method of Parent we use the \"super()\" function.  This makes no functional difference in our code here but it has some advantages in maintainability and when implementing multiple inheritance.  \n",
    "However, there are some 'gotchas' that can arise with super and multiple inheritance; you can check out this companion DataCamp tutorial to learn more about it.  (Google \"Learn more about multiple inheritance & super()\")\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "Lets continue the family tree, to create a Grandchild class that inherits from SuperChild we use the same super syntax in its __init__ method, and viola.  \n",
    "\n",
    "If you're using inheritance its sometimes hard to remember what attributes annnd methods your class has at the end of it all.  If you're using an IDE, then generally you can use tab complete to get a list of suggestions.  However, if you want to get the info from the console, you can use either \"help\" or the \"dir\" function.  The \"help\" is a good option in most cases, but it will onnly include public methods in its output.  \n",
    "\n",
    "Using \"dir\" will print a fairly exhaustive list of what your class has under the covers.  The list includes methods that come with our class object by default.  Near the end of the list, you see all the methods and attributes that you personaly programmed into the SocialMedia class.  The \"dir\" can definitely come in handy, but a warning from the documentation, \"dir is supplied primarily as a convenience of use at an interactive prompt\"  SO its not advised to use it in your scripts.  \n",
    "\n",
    "\n",
    "We just covered more about how powerful inheritance can be.  In the exercise, you'll use multilevel inheritance to create a new Tweet class.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6b57636c-58c3-4f76-bd37-c07321f602fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n",
      "ADAM\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "When using ParentClass's __init__ method, why pass in parents' argument too ? ~~~~~~~\n",
    "\n",
    "In short, you might want to do something to the inputs before passing them on.  \n",
    "Theres also no guarantee you gave the subclass the arguments with the same names.  \n",
    "I just as easily could have named the argument in `CapA` cap_a_name, \n",
    "python doesnt know what youve called things or if you want to do things to the inputs first.  \n",
    "So its up to you to tell it the params.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class A:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def print_name(self):\n",
    "        print(self.name)\n",
    "\n",
    "\n",
    "class CapA(A):\n",
    "    def __init__(self, name):\n",
    "        #super().__init__(self, name.upper())  ######################################################################\n",
    "                         ############ here with no \"self\" from Parent, but modified \"name\" argument  ++++++++++++++++\n",
    "        #super().__init__(self, name)   # __init__() takes 2 positional arguments but 3 were given  +++++++++++++++++\n",
    "        #super().__init__()             # __init__() missing 1 required positional argument: 'name'  ++++++++++++++++\n",
    "        #super().__init__(self)         # <__main__.CapA object at 0x7f2487ef19d0>   ++++++++++++++++++++++++++++++++\n",
    "        super().__init__(name.upper())\n",
    "        #super().__init__(name)\n",
    "        #A.__init__()                   # __init__() missing 2 required positional arguments: 'self' and 'name'   +++\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# *******************************************************************************************************************\n",
    "# *******************************************************************************************************************\n",
    "# *******************************************************************************************************************\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "\n",
    "a = A(\"adam\")\n",
    "cap_a = CapA(\"adam\")\n",
    "\n",
    "a.print_name()\n",
    "cap_a.print_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "635e1755-b9d6-49cd-ae26-7f8e921b5453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm parent\n",
      "I'm a super child\n",
      "I'm a grandchild\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Import ParentClass object\\nfrom .parent_class import ParentClass\\n\\n\\n# Create a child class with inheritance\\nclass ChildClass(ParentClass):\\n    def __init__(self):\\n        # Call parent\\'s __init__ method\\n        ParentClass.__init__(self)\\n        # Add attribute unique to child class\\n        self.child_attribute = \"I\\'m a child class attribute\"        '"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Parent:\n",
    "    def __init__(self):\n",
    "        print(\"I'm parent\")\n",
    "        \n",
    "        \n",
    "class Child(Parent):\n",
    "    def __init__(self):\n",
    "        Parent.__init__()  #### Should be a \"self\" inside ?\n",
    "        print(\"I'm child\")\n",
    "        \n",
    "        \n",
    "class SuperChild(Parent):\n",
    "    def __init__(self):\n",
    "        super().__init__()  #########################################################################################\n",
    "        print(\"I'm a super child\")\n",
    "        \n",
    "        \n",
    "class GrandChild(SuperChild):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"I'm a grandchild\")\n",
    "        \n",
    "        \n",
    "grandchild = GrandChild()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# Import ParentClass object\n",
    "from .parent_class import ParentClass\n",
    "\n",
    "\n",
    "# Create a child class with inheritance\n",
    "class ChildClass(ParentClass):\n",
    "    def __init__(self):\n",
    "        # Call parent's __init__ method\n",
    "        ParentClass.__init__(self)\n",
    "        # Add attribute unique to child class\n",
    "        self.child_attribute = \"I'm a child class attribute\"        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748c53b-509e-4f93-afa9-eae43dc9eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "\n",
    "# st_class.py\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()  #### ???? Why the Intermediate Data Importing institor using this \n",
    "        self.num_tweets = 0\n",
    "        self.file = open('tweets.txt', 'w')\n",
    "        \n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\\\n')\n",
    "        tweet_list.append(status)\n",
    "        \n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "        \n",
    "#####################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba932dc-893c-4f76-8341-4179a4b44b51",
   "metadata": {},
   "source": [
    "## Exploring with dir and help\n",
    "\n",
    "A new method has been added to the Document class. The method is a convenience wrapper around the plot_counter() function you wrote in an earlier exercise. In this exercise, you'll use dir() and help() to identify how to utilize the new method.\n",
    "Instructions 1/3\n",
    "35 XP\n",
    "\n",
    "    Question 1\n",
    "    import the \"text_analyzer\" package.\n",
    "    Define \"my_doc\" as an instance of \"Document\" with the \"text=\" stored in \"datacamp_tweets\". datacamp_tweets has been pre-loaded in your environment.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Run \"help()\" on the plot method you discovered with \"dir()\" to see how to properly use the functionality.\n",
    "    Plot my_doc's word counts using the new plot method.\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    Use \"dir\" to show all of my_doc's methods and attributes. What is the name of the new plot method from the resulting list.\n",
    "plot_word_counts\n",
    "plot_words\n",
    "plot_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5bf560a7-52b4-414d-81f2-65f43e7cf0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_count_words', '_tokenize', 'text', 'tokens', 'word_counts']\n"
     ]
    }
   ],
   "source": [
    "# Import needed package\n",
    "import text_analyzer\n",
    "\n",
    "\n",
    "datacamp_tweets = \" RT @bpolitics: .@krollbondrating's Christopher Whalen says Clinton is the weakest Dem candidate in 50 years https://t.co/pLk7rvoRSn https:/ RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3 Njihuni me Zonjn Trump !!! | Ekskluzive https://t.co/4KmsQi47VD Your an idiot she shouldn't have tried to grab trump after the fact she's an idiot https://t.co/lpASyeNVpG RT @AlanLohner: The anti-American D.C. elites despise Trump for his Ame\"\n",
    "\n",
    "# Create instance of document\n",
    "my_doc = Document(datacamp_tweets)\n",
    "\n",
    "\n",
    "\n",
    "print(dir(my_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc5206-b44b-4483-bb7f-47c4e4661bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/jhu/datacmap_data_engineering/text_analyzer/counter_utils.py  -------------------------------------------------\n",
    "\n",
    "# Import needed functionality\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_counter(counter, n_most_common=5):\n",
    "    \n",
    "    # Subset the n_most_common items from the input counter\n",
    "    top_items = counter.most_common(n_most_common)\n",
    "    \n",
    "    # Plot `top_items`\n",
    "    #plot_counter_most_common(top_items)  ###########################################################################\n",
    "    plt.plot(list(counter.keys())[:n_most_common], \n",
    "             list(counter.values())[:n_most_common])  ###############################################################\n",
    "    plt.show(block=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def sum_counters(counters):\n",
    "    # Sum the inputted counters\n",
    "    #return sum(counters.values(), Counter())  ### I think its a mistake ############################################\n",
    "    \n",
    "    print(sum(counters.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd14ec-92f9-4985-bfae-b50676b2b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/social_media.py \n",
    "from text_analyzer import Document\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "\n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return SocialMedia.filter_word_counts(self.word_counts, first_char='#')  ####################################\n",
    "\n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return SocialMedia.filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/document.py \n",
    "# Import function to perform tokenization\n",
    "from token_utils import tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        #return tokenize(self.text)\n",
    "        return self.text.split()  ###################################################################################\n",
    "\n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        #return Counter([i.string for i in self.tokens])\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "    def plot_counter(self, n_most_common=5):\n",
    "        # Subset the n_most_common items from the input Counter object\n",
    "        self.top_items = self.most_common(n_most_common)\n",
    "                         ################ Here why use \"self.most_common\" instead of \"self.word_counts.most_common\"\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        \n",
    "        plt.plot([i[0] for i in self.top_items],\n",
    "                 [i[1] for i in self.top_items])  ###################################################################\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def filter_word_counts(self, first_char):\n",
    "        \"\"\"Pass in a Counter object, filter with 'first_char'\"\"\"\n",
    "        return Counter({ k: v for k, v in self.items() if first_char in k})  ########################################\n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer_script.py \n",
    "# Import needed functionality\n",
    "from text_analyzer import plot_counter, sum_counters\n",
    "from collections import Counter\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "# thanks for \"from .document import Document\" in \"__init__\", no need to packag.module.class #########################\n",
    "from text_analyzer import Document, SocialMedia\n",
    "import json\n",
    "\n",
    "\n",
    "tweets_data = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        tweets_data = tweets_data + ' ' + str(tweet['text'])  #######################################################\n",
    "\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = Document(text=tweets_data)\n",
    "\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document.text[:3])\n",
    "print(my_document.tokens[:3])\n",
    "print(my_document.word_counts)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# create a new document instance from datacamp_tweets\n",
    "datacamp_doc = Document(tweets_data)\n",
    "\n",
    "# print the first 5 tokens from datacamp_doc\n",
    "print(datacamp_doc.tokens[:3])  ### It becomes a list of tuples\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "top_15_words = datacamp_doc.word_counts.most_common(15)  ### It becomes a list of tuples\n",
    "print(top_15_words)\n",
    "\n",
    "print(datacamp_doc.word_counts)   ###################################################################################\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "tweets = SocialMedia(text=tweets_data)\n",
    "\n",
    "hashtags = tweets.hashtag_counts\n",
    "print(hashtags)\n",
    "mentions = tweets.mention_counts\n",
    "print(mentions)\n",
    "\n",
    "print(type(hashtags))   ## <class 'collections.Counter'> object\n",
    "\n",
    "\n",
    "SocialMedia.plot_counter(hashtags, 10)  #############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17550fbe-d10a-4378-a149-9f1970db6c2d",
   "metadata": {},
   "source": [
    "## Creating a grandchild class\n",
    "\n",
    "In this exercise you will be using inheritance to create a Tweet class from your SocialMedia class. This new grandchild class of Document will be able to tackle Twitter specific details such as retweets.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Complete the class statement so that Tweets inherits from \"SocialMedia\". \"SocialMedia\" has already been loaded in your environment.\n",
    "#    Use super() to call the \"__init__\" method of the parent class.\n",
    "    Define \"retweet_text\". Use help() to complete the call to \"filter_lines\" with the correct parameter name. filter_lines has already been loaded in your environment.\n",
    "    return \"retweet_text\" from _process_retweets as an instance of SocialMedia.\n",
    "\n",
    "Hint\n",
    "\n",
    "    The class statement will look similar to when you defined SocialMedia with SocialMedia(Document).\n",
    "    Remember to pass text to your call to SocialMedia's __init__ method using super().\n",
    "    The 2nd param shown in help(filter_lines) is what's needed to complete the call.\n",
    "    Calling SocialMedia like a function will complete the definition of _process_retweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b0c7c-6ec8-4470-bb1c-e4affd167b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Tweet class that inherits from SocialMedia\n",
    "class Tweets(SocialMedia):\n",
    "    def __init__(self, text):\n",
    "        # Call parent's __init__ with super()\n",
    "        super()__init__()   #########################################################################################\n",
    "        # Define retweets attribute with non-public method\n",
    "        self.retweets = self._process_retweets()   ##################################################################\n",
    "                        #+++++++++++++++++++++++ Just use \"self._process_retweets\" meaning our aproach correct ++++++\n",
    "    def _process_retweets(self):\n",
    "        # Filter tweet text to only include retweets\n",
    "        retweet_text = filter_lines(self.text, first_char='RT')\n",
    "        # Return retweet_text as a SocialMedia object\n",
    "        return ____(retweet_text)   #### ????????????????????????????????????????????????????????????????????????????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba49f49-c7a0-41a0-9aee-2cc81462a906",
   "metadata": {},
   "source": [
    "# *******************************************************************************************************************\n",
    "\n",
    "# Here we should have a completelly thinking on each immplementation.  How does this institutor handle such task, whats the difference between my approach and his?  And what might be in his function and class\n",
    "\n",
    "\n",
    "\n",
    "A tweet looks like this, starting with \"RT\" if its a reweet, and followed by other metadata:\n",
    "\n",
    "++\n",
    "RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3 Njihuni me Zonjn Trump !!! | Ekskluzive https://t.co/4KmsQi47VD Your an idiot she shouldn't have tried to grab trump after the fact she's an idiot https://t.co/lpASyeNVpG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5642c8e8-f20b-490b-aee3-92cd5e100037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @bpolitics: .@krollbondrating's Christopher Whalen says Clinton is the weakest Dem candidate in 50 years https://t.co/pLk7rvoRSn https:/\n",
      "RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3\n",
      "None\n",
      "None\n",
      "RT @AlanLohner: The anti-American D.C. elites despise Trump for his America-first foreign policy. Trump threatens their gravy train. https:\n",
      "RT @BIackPplTweets: Young Donald trump meets his neighbor  https://t.co/RFlu17Z1eE\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @HouseCracka: 29,000+ PEOPLE WATCHING TRUMP LIVE ON ONE STREAM!!!\n",
      "\n",
      "https://t.co/7QCFz9ehNe\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  https\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  https\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearly\n",
      "None\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET https\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "None\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET https\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearly\n",
      "None\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9N\n",
      "None\n",
      "RT @Norsu2: Nightmare WI poll for Ted Cruz has Kasich surging: Trump 29, Kasich 27, Cruz 25. https://t.co/lJsgbLYY1P #NeverTrump\n",
      "RT @thehill: WATCH: Protester pepper-sprayed point blank at Trump rally https://t.co/B5f65Al9ld https://t.co/skAfByXuQc\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9N\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/\n",
      "None\n",
      "None\n",
      "None\n",
      "RT @DebbieStout5: Wow! Last I checked it was just 12 points &amp; that wasn't more than a day ago. Oh boy Trump ppl might want to rethink http\n",
      "RT @tyleroakley: i'm a messy bitch, but at least i'm not voting for trump\n",
      "RT @vandives: Trump supporters r tired of justice NOT being served. There's no justice anymore. Hardworking Americans get screwed. That's n\n",
      "None\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "None\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "None\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "None\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNN\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will n\n",
      "None\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNN\n",
      "None\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "None\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will n\n",
      "None\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation P\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "None\n",
      "None\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educat\n",
      "None\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation P\n",
      "None\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educat\n",
      "None\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @T\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didnt come out of nowhere.\" Hillary\n",
      "https\n",
      "None\n",
      "None\n",
      "None\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @T\n",
      "None\n",
      "None\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didnt come out of nowhere.\" Hillary\n",
      "https\n",
      "None\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating t\n",
      "None\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating t\n",
      "None\n",
      "None\n",
      "RT @GlendaJazzey: Donald Trumps Campaign Financing Dodge, @rrotunda https://t.co/L8flI4lswG via @VerdictJustia\n",
      "None\n",
      "None\n",
      "None\n",
      "RT @TUSK81: LOUDER FOR THE PEOPLE IN THE BACK https://t.co/hlPVyNLXzx\n",
      "RT @loopzoop: Well...put it back https://t.co/8Yb7BDT5VM\n",
      "None\n",
      "RT @claytoncubitt: Stop asking Bernie supporters if theyll vote for Hillary against Trump. We got a plan to beat Trump already. Called Ber\n",
      "None\n",
      "RT @akaMaude13: Seriously can't make this up. What a joke. #NeverTrump  https://t.co/JkTx6mdRgC\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "###from text_analyzer import Document\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()  #--------------------------------------------------------------\n",
    "        self.mention_counts = self._count_mentions()  #--------------------------------------------------------------\n",
    "\n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return SocialMedia.filter_word_counts(self.word_counts, first_char='#')  ####################################\n",
    "\n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return SocialMedia.filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "# Import function to perform tokenization\n",
    "###from token_utils import tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        #return tokenize(self.text)\n",
    "        return self.text.split()  ###################################################################################\n",
    "\n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        #return Counter([i.string for i in self.tokens])\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "    def plot_counter(self, n_most_common=5):\n",
    "        # Subset the n_most_common items from the input Counter object\n",
    "        self.top_items = self.most_common(n_most_common)\n",
    "                         ################ Here why use \"self.most_common\" instead of \"self.word_counts.most_common\"\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        \n",
    "        plt.plot([i[0] for i in self.top_items],\n",
    "                 [i[1] for i in self.top_items])  ###################################################################\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def filter_word_counts(self, first_char):\n",
    "        \"\"\"Pass in a Counter object, filter with 'first_char'\"\"\"\n",
    "        return Counter({ k: v for k, v in self.items() if first_char in k})  ########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a Tweet class that inherits from SocialMedia\n",
    "class Tweets(SocialMedia):\n",
    "    def __init__(self, text):\n",
    "        # Call parent's __init__ with super()\n",
    "        super().__init__(text)   ##----------------------------------------------------------------------------------\n",
    "        # Define retweets attribute with non-public method\n",
    "        self.retweets = self._process_retweets()\n",
    "                        ##------------------- \"self._process_retweets\" meaning our aproach correct ------------------\n",
    "    def _process_retweets(self):\n",
    "        # Filter tweet text to only include retweets\n",
    "        retweet_text = self.filter_lines(first_char='RT')  ##--------------------------------------------------------\n",
    "        # Return retweet_text as a SocialMedia object\n",
    "        return SocialMedia(retweet_text)   #### ?????????????????????????????????????????????????????????????????????\n",
    "\n",
    "\n",
    "    def filter_lines(self, first_char):\n",
    "        # The function work a filter, keep input 'text' start with 'RT'\n",
    "        # Whats the input data? joined long string, or individual tweet['text'].  Can we do it both way\n",
    "\n",
    "        if self[:2]==first_char:\n",
    "            return self\n",
    "'''\n",
    "        rt = str()\n",
    "        for i in self:\n",
    "            if i[:2] == first_char:\n",
    "                rt = rt + ' ' + str(i)\n",
    "\n",
    "        return rt\n",
    "'''\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Maybe the input 'text' should be each tweet['text']? Thus we need to change\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "tweets_data = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        tweets_data = tweet['text']\n",
    "        reweets = Tweets.filter_lines(tweets_data, 'RT')\n",
    "        print(reweets)\n",
    "        \n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# I know the code works, but now I want to put my module into real world production, with looker or something to\n",
    "# visualization on a dashboard, and grab the Tweet record fo something like #Tump hashtag or else\n",
    "\n",
    "# I think it could be very interesting, and can be immplementated to other areas\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f6434f78-7b0a-49f6-8b36-2790e61c1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'#Trump': 3, 'is': 3, 'the': 2, 'bad': 1, 'guy,': 1, 'not': 1, 'vote': 1, 'him.': 1, '#John': 1, 'he': 1, 'good': 1, 'fellow.': 1, 'our': 1, 'hero.': 1, 'saved': 1, 'world': 1})\n",
      "dict_keys(['#Trump', 'is', 'the', 'bad', 'guy,', 'not', 'vote', 'him.', '#John', 'he', 'good', 'fellow.', 'our', 'hero.', 'saved', 'world'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'#Trump': 3, '#John': 1})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "tweets = \"#Trump is the bad guy, not vote him.  #John he is good fellow. #Trump is our hero. #Trump saved the world\"\n",
    "tweets_list = tweets.split()\n",
    "\n",
    "word_counts = Counter(tweets_list)\n",
    "print(word_counts)\n",
    "\n",
    "#print(dir(word_counts))\n",
    "print(word_counts.keys())\n",
    "\n",
    "[*filter(lambda x: '#' in x, word_counts)]\n",
    "\n",
    "Counter({ k: v for k, v in word_counts.items() if \"#\" in k})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7f0ef-6fbe-414e-b4e1-9983ca00473c",
   "metadata": {},
   "source": [
    "## Using inherited methods\n",
    "\n",
    "You've now defined a \"Tweets\" class that's inherited methods from both Document and SocialMedia. In this exercise, you'll use inherited methods to visualize text from both tweets and retweets.\n",
    "\n",
    "Be aware that this is real data from Twitter and as such there is always a risk that it may contain profanity or other offensive content (in this exercise, and any following exercises that also use real Twitter data).\n",
    "Instructions 1/3\n",
    "35 XP\n",
    "\n",
    "    Question 1\n",
    "    import your \"text_analyzer\" package.\n",
    "#    Define \"my_tweets\" as an instance of Tweets using the \"datacamp_tweets\" data that has been pre-loaded into your environment.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "#    Use the \"plot_counts()\" method to plot the top 'hashtag_counts'.\n",
    "    Make sure to check the documentation for \"my_tweets.plot_counts\".\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 3\n",
    "    Use the \"plot_counts()\" method of the \"retweets\" attribute to plot the most used hashtags in the retweets subset of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d50df9-87a2-45e1-a69e-1d1b26c42f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed package\n",
    "from text_analyzer import Document, SocialMedia, Tweets\n",
    "\n",
    "# Create instance of Tweets\n",
    "my_tweets = Tweets(datacamp_tweets)\n",
    "\n",
    "\n",
    "\n",
    "my_tweets.plot_counts()\n",
    "\n",
    "\n",
    "\n",
    "my_tweets.retweet_text.\n",
    "\n",
    "\n",
    "\n",
    "Use the plot_counts() method of the retweets attribute to plot the most used hashtags in the retweets subset of the data.\n",
    "\n",
    "# Import needed package\n",
    "import text_analyzer\n",
    "\n",
    "# Create instance of Tweets\n",
    "my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
    "\n",
    "# Plot the most used hashtags in the retweets\n",
    "my_tweets.retweets.plot_counts('hashtag_counts')\n",
    "\n",
    "# Great work! Your Tweets class can easily visualize Twitter data with little code thanks to inheritance \n",
    "# and clever usage of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aaa206-043c-4739-9135-0434f5772046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final code looks like this:\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/document.py \n",
    "# Import function to perform tokenization   ### from .token_utils import tokenize\n",
    "from token_utils import tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "\n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        #return tokenize(self.text)\n",
    "        return self.text.split()\n",
    "\n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        #return Counter([i.string for i in self.tokens])\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "    def plot_counter(self, n_most_common=5):\n",
    "        # Subset the n_most_common items from the input Counter object\n",
    "        self.top_items = self.most_common(n_most_common)\n",
    "        # Plot `top_items`\n",
    "        #plot_counter_most_common(top_items)  ###################################################################\n",
    "\n",
    "        plt.style.use('bmh')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "        ax.bar([i[0] for i in self.top_items],\n",
    "               [i[1] for i in self.top_items])\n",
    "\n",
    "        #plt.title(self, fontsize=14)  how to set the title of each plot?  thinking\n",
    "        #ax.set_xticklabels([i[0] for i in self.top_items], rotation=45)\n",
    "        ax.set_ylabel('Number of counts')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def filter_word_counts(self, first_char):\n",
    "        \"\"\"Pass in a Counter object, filter with 'first_char'\"\"\"\n",
    "        return Counter({ k: v for k, v in self.items() if first_char in k})  ####################################\n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/social_media.py \n",
    "from text_analyzer import Document\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "\n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return SocialMedia.filter_word_counts(self.word_counts, first_char='#')  ################################\n",
    "\n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return SocialMedia.filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/tweets.py \n",
    "# Import parent class for inheritance\n",
    "from text_analyzer import SocialMedia\n",
    "\n",
    "\n",
    "# Define a Tweet class that inherits from SocialMedia\n",
    "class Tweets(SocialMedia):\n",
    "    def __init__(self, text):\n",
    "        # Call parent's __init__ with super()\n",
    "        super().__init__(text)   ###\n",
    "        # Define retweets attribute with non-public method\n",
    "        self.retweets = self._process_retweets() #---------------------------------------\n",
    "                        #------------------- \"self._process_retweets\" meaning our aproach correct ------------------\n",
    "    def _process_retweets(self):\n",
    "        # Filter tweet text to only include retweets\n",
    "        retweet_text = self.filter_lines(first_char='RT')  ##----------------------------\n",
    "        # Return retweet_text as a SocialMedia object\n",
    "        #return SocialMedia(retweet_text)\n",
    "        print(retweet_text)\n",
    "        return retweet_text\n",
    "\n",
    "\n",
    "    def filter_lines(self, first_char):\n",
    "        # The function work a filter, keep input 'text' start with 'RT'\n",
    "        #print(self.text)     This is a tweet['text'], the string\n",
    "        if self.text[:2]==first_char:  # The self is the object, we need to use its attribute - 'text' -------------\n",
    "            return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer_script.py \n",
    "'''# Import needed functionality\n",
    "from text_analyzer import plot_counter, sum_counters\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "word_counts = Counter('ascwcsyswsscsfwwrrgrddewdqyc')\n",
    "\n",
    "# Sum word_counts using \"sum_counters\" from \"text_analyzer\"\n",
    "word_count_totals = sum_counters(word_counts)\n",
    "\n",
    "# Plot word_count_totals using plot_counter from text_analyzer\n",
    "plot_counter(word_counts)\n",
    "'''\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Because we used \"from .document import Document, xx\" in \"__init__.py\", no need pkg.module.class\n",
    "from text_analyzer import SocialMedia, Tweets, Document\n",
    "import json\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Lets find the most common words people are tweeting at this moment (say its a 10 mins tweet stream)\n",
    "f_text = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        text = tweet['text']\n",
    "        f_text = f_text + ' ' + text\n",
    "\n",
    "# create a new document instance from datacamp_tweets\n",
    "datacamp_doc = Document(f_text)\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "top_15_words = datacamp_doc.word_counts.most_common(15)\n",
    "print(top_15_words)\n",
    "\n",
    "#print(datacamp_doc.word_counts)  # Image what will happened\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Analysis full batch of tweet['text'], store in one str and plot the most-common hashtags & mentions\n",
    "f_text = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        text = tweet['text']\n",
    "        f_text = f_text + ' ' + text\n",
    "\n",
    "\n",
    "tweets = SocialMedia(text=f_text)\n",
    "\n",
    "# Lets print top-5 hashtags & mentons on the screen\n",
    "hashtags = tweets.hashtag_counts\n",
    "print(hashtags.most_common(5))\n",
    "mentions = tweets.mention_counts\n",
    "print(mentions.most_common(5))\n",
    "\n",
    "# Then lets plot most common 5 hashtags and mentions\n",
    "SocialMedia.plot_counter(hashtags, 5)\n",
    "SocialMedia.plot_counter(mentions, 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Analysis full batch of tweet['text'], store in one str and plot the most-common hashtags & mentions\n",
    "f_text = str()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        text = tweet['text']\n",
    "        f_text = f_text + ' ' + text\n",
    "\n",
    "\n",
    "my_tweets = SocialMedia(f_text)\n",
    "\n",
    "# Plot the most used hashtags in the retweets\n",
    "hashtags = my_tweets.hashtag_counts\n",
    "print(hashtags)\n",
    "\n",
    "SocialMedia.plot_counter(hashtags, 6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# With a list to store each tweet['text'], analysis one by one; RTs,  hashtags, mentions, and plot them\n",
    "words = list()\n",
    "with open('tweets3.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        tweet = json.loads(i)\n",
    "        text = tweet['text']\n",
    "        words.append(text)\n",
    "\n",
    "\n",
    "i = 11\n",
    "\n",
    "tweet = Tweets(words[i])\n",
    "print(tweet.text)\n",
    "\n",
    "rt = tweet.retweets\n",
    "Tweets.plot_counter(rt.hashtag_counts, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6f985-802a-4646-9440-c4e75467cea0",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**One of the big Software Engineering concepts that all Python users benefit from is Documentation.  Documentation in Python can take the form of comments.  Comments in Python are led by the pound symbol as you see here.  They can sprinkle in information about your code for future collaborators.  Another way of documenting code is to use docstrings.  Docstrings are invoked by the use of triple quotation marks like you see before in Python OOP course.  They are typically used to document functions classes, and scripts for your users.  \n",
    "\n",
    "# Lets look at both these in a little more detail.  \n",
    "Comments are used inline to document what a particular line of code is doing and why.  They can appear on their own line or at the end of a line of code.  A big difference between docstrings and comments is that comments will not be seen by your users unless they are looking into your source code.  The goal of comments is to make your code more readable for both yourself and collaborators.  \n",
    "\n",
    "There is some debateon the usefulness of comments.  Take a moment to look at these comments.  As you can see they don't ass much value: unless the code is trying to teach someone about Python basics, then these could be useful comments.  So its important to know your audience when commenting.  \n",
    "\n",
    "# However, a good rule is that comments should explain why a line od code is doing something and not what the line of code is doing.  \n",
    "\n",
    "Below is the same code with different comments to explain the why of the code.  In my opinion, over-commented code isn't nearly as big of a headache as under-commented code.  \n",
    "# If you ever have question of wheather or not a comment is useful, I would suggest adding the comment.  \n",
    "\n",
    "\n",
    "# Comments are documentation for yourself and collaborators, docstrings are documentation for your users.  \n",
    "Docstrings are what Python outputs wheather a user calls help on your functions and classes.  Lets look at the anatomy of a docstring.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "The first section describe the functionality of what we're documenting.  Next, we document the parametersand return value of our function.  We use this particular syntax with the colons by convention so that downstream tools can take our docstrings and convert them into website based documentation.  You can see an example of a webpage generated from a docstring formatted like ours, at below link which shows the documentation for the popular Flask package.  (Google Example webpage generated from a docstringin the Flask package).  \n",
    "\n",
    "Last, we can document example usage and expected output.  The 3 chevrons show the example function call and the next line will represent the expected output.  Here we see a docstring actually filled out to describe a function and its usage.  It contains a brief description, information on the parameter & return values, and an example showing how the function is used.  In the case of this simple function, the optional details section wouldn't add much value so its been omitted.  In addition to the docstring, we see comments explaining why the code was written a certain way, as opposed to what the code is doing.  \n",
    "\n",
    "Now that we've written the docstring for the square function, users can access it by calling help.  When they do they'll see this print out showing all the information they'd need to understand what it does and use it properly.  Note, as mentioned before, the users don't see our comments that describe our implementation details to future colaborators.  \n",
    "\n",
    "\n",
    "We just covered how to write effective comments and docstrings.  Lets jump into some practices. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define people as 5\n",
    "people = 5\n",
    "\n",
    "\n",
    "# Multiply people by 3\n",
    "people * 3\n",
    "\n",
    "\n",
    "\n",
    "# There will be 5 people attending the party\n",
    "people = 5\n",
    "\n",
    "\n",
    "# We need 3 piece of pizza per person\n",
    "people * 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def function(x):\n",
    "    \"\"\"High level description of function\n",
    "    \n",
    "    Additional details on function\n",
    "    \n",
    "    :param x: description of parameter x\n",
    "    :return: description of return value\n",
    "    \n",
    "    >>> # Example function usage\n",
    "    Expected output of example function usage\n",
    "    \"\"\"\n",
    "    \n",
    "    # function body code\n",
    "\n",
    "\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Square the number x\n",
    "    \n",
    "    :param x: number to square\n",
    "    :return: x squared\n",
    "    \n",
    "    >>> square(2)\n",
    "    4\n",
    "    \"\"\"\n",
    "    \n",
    "    # `x * x` is faster than ``x ** 2`\n",
    "    # reference: https://stackoverflow.com/a/29055266/5731525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293fbfd-ee38-43b2-bd69-01d93c52b6d9",
   "metadata": {},
   "source": [
    "## Identifying good comments\n",
    "\n",
    "We learned about what characteristics make a 'good' comment. In this exercise, you'll apply this knowledge to identify a function that utilizes comment best practices.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    print the text variable that has been pre-loaded into your environment.\n",
    "    print the result of calling the function with more useful commenting on text.\n",
    "\n",
    "Hint\n",
    "\n",
    "    Good comments don't just reiterate what the code is doing, but they give additional context to the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69b6170-98eb-4273-ae10-48ffa8898d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High level description of function        Additional details on function        :param x: description of parameter x    :return: description of return value        >>> # Example function usage    Expected output of example function usage    \n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "text =     \"High level description of function\\\n",
    "    \\\n",
    "    Additional details on function\\\n",
    "    \\\n",
    "    :param x: description of parameter x\\\n",
    "    :return: description of return value\\\n",
    "    \\\n",
    "    >>> # Example function usage\\\n",
    "    Expected output of example function usage\\\n",
    "    \"\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_0(text):\n",
    "    # match and extract dollar amounts from the text\n",
    "    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n",
    "\n",
    "def extract_1(text):\n",
    "    # return all matches to regex pattern\n",
    "    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n",
    "\n",
    "# Print the text\n",
    "print(text)\n",
    "\n",
    "# Print the results of the function with better commenting\n",
    "print(extract_0(text))\n",
    "\n",
    "print(extract_1(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06141aff-cdb5-45b7-8763-be00d458df74",
   "metadata": {},
   "source": [
    "## Identifying proper docstrings\n",
    "\n",
    "We covered how to write fully-fledged docstrings. Before writing one of your own, this exercise will help you practice by having you identify a properly formatted docstring.\n",
    "\n",
    "In this exercise, you'll be using the functions \"goldilocks()\", \"rapunzel()\", \"mary()\", and \"sleeping_beauty()\" which have been loaded in your environment.\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "\n",
    "    Question 1\n",
    "    Run \"help()\" on each of the 4 functions to view their docstrings.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Question 2\n",
    "    Define result using the function that has the most complete docstring; only 1 of the 4 contains all the sections we covered. Call the function without any parameters.\n",
    "    print the result of the most well documented function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d04e00-76c9-48e3-a5a5-a2c8aad3da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the help on all 4 functions\n",
    "help(goldilocks)\n",
    "____(rapunzel)\n",
    "help(____)\n",
    "____(____)\n",
    "\n",
    "\n",
    "\n",
    "# Run the help on all 4 functions\n",
    "help(goldilocks)\n",
    "help(rapunzel)\n",
    "help(mary)\n",
    "help(sleeping_beauty)\n",
    "\n",
    "# Execute the function with most complete docstring\n",
    "result = rapunzel()\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f281d4-1dcf-4bc5-a6bb-a48c5c7e68ae",
   "metadata": {},
   "source": [
    "## Writing docstrings\n",
    "\n",
    "We just learned some about the benefits of docstrings. In this exercise, you will practice writing docstrings that can be utilized by a documentation generator like Sphinx.\n",
    "\n",
    "Note that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Complete the portions of the docstring that document the parameters.\n",
    "    Complete the portion of the docstring describing the return value.\n",
    "    Complete the example function usage in the docstring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b11cb1-d0ea-4c02-8597-ead8adbc7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function's docstring\n",
    "def tokenize(text, regex=r'[a-zA-z]+'):\n",
    "  \"\"\"Split text into tokens using a regular expression\n",
    "\n",
    "  :____ text: text to be tokenized\n",
    "  :param ____: regular expression used to match tokens using re.findall \n",
    "  :return: a list of resulting tokens\n",
    "\n",
    "  >>> ____('the rain in spain')\n",
    "  ____\n",
    "  \"\"\"\n",
    "  return re.findall(regex, text, flags=re.IGNORECASE)\n",
    "\n",
    "# Print the docstring\n",
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f12e60e-0d06-49be-878b-b6349b1797d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tokenize in module __main__:\n",
      "\n",
      "tokenize(text, regex='[a-zA-z]+')\n",
      "    Split text into tokens using a regular expression\n",
      "    \n",
      "    :param text: text to be tokenized\n",
      "    :param regex: regular expression used to match tokens using re.findall \n",
      "    :return: a list of resulting tokens\n",
      "    \n",
      "    >>> tokenize('the rain in spain')\n",
      "    ['the', 'rain', 'in', 'spain']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete the function's docstring\n",
    "def tokenize(text, regex=r'[a-zA-z]+'):\n",
    "  \"\"\"Split text into tokens using a regular expression\n",
    "\n",
    "  :param text: text to be tokenized\n",
    "  :param regex: regular expression used to match tokens using re.findall \n",
    "  :return: a list of resulting tokens\n",
    "\n",
    "  >>> tokenize('the rain in spain')\n",
    "  ['the', 'rain', 'in', 'spain']\n",
    "  \"\"\"\n",
    "  return re.findall(regex, text, flags=re.IGNORECASE)\n",
    "\n",
    "# Print the docstring\n",
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f36df9-4009-4dee-883c-ade38da07a25",
   "metadata": {},
   "source": [
    "## Readability counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Another important step to writing a maintainable project is readable code.  Luckily, Python has a big focus on readability, and it comes with a list of guidelines to help write good code.  These guidelines are known as the \"Zen of Python\", and you can view them through the command \"import this\".  Here we see a abridged version in the slide.  Notice the item , \"readability counts\", and the rest of the items can guide us in this quest for readability.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# One way to aid in readability is with good naming.  \n",
    "Look at below two functions.  Both implement the same logic.  However, if we believe \"readability counts\", then the 'is_boiling' function is a better option.  The 'is_boiling' function describes what it's doing thanks to descriptive naming.  This is known as self-documenting code.  \n",
    "\n",
    "However, remember that under-commented is a bigger issue than over-commented code; if you're ever in doubt, add comments.  \n",
    "\n",
    "A warning about descriptive names.  It's possible to go too far.  Modern IDEs have auto-complete so it might not seen like a burden to type long names, but long names can  make code hard to read, as you see here.  Note, even if your code is self-documenting, your users will appreciate the ability to call help and see all the good information a docstring can provide.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# Another way to keep your project readable is by writing in simple maintainable units of code.  \n",
    "\n",
    "Lets take a look at an example by writing a function to make a pizza.  Take a look at this code to make a pizza.  Notice that the full definition doesn't fit on the slide.  Although we're working with a small screen, not being able to fit your function on the screen is a sign that it maybe should be refactored.  \n",
    "\n",
    "A less obvious issue is that we have a few different processes happening that could stand on their own.  We're making dough and then making a sauce; we might want to be able to make dough outside of the pizza process.  \n",
    "\n",
    "Lets do some refactoring.  Take a second to look at this refactored function.  Its easier to see what's happening, in both a functional sense and a literal one since we were ablt to fully fit it on the screen.  By breaking process out into their own descriptively named functions we can see the high-level process of making a pizza at a glance.  \n",
    "\n",
    "An additional benefit of defining these smaller functions is that we now have more modular code that we can easily plug into different recipes that might call for our homemade marinara.  These also make writing tests easier, which we'll soon be covering.  \n",
    "\n",
    "\n",
    "# Our rewrites came about thanks to a couple warning signs.  \n",
    "They were that our function was a bit long and we had separate processes happening.  \n",
    "# *******************************************************************************************************************\n",
    "You should atrive for your functions to accomplish one and only one thing.  In our pizza example, we were using comments as section headers to denote different processes; if you're ever doing that then its a good bet that your code should be split into smaller functions.  \n",
    "\n",
    "Another warning sign that your function is doing too much is if its hard to think of a good meaningful name for it. \n",
    "# *******************************************************************************************************************\n",
    "Unfortunately, you might not notice your code is hard to read until trying to read it the next day.  \n",
    "\n",
    "\n",
    "\n",
    "Just strive to do your best, and to repeat once more: document your code with comments and docstrings.  \n",
    "\n",
    "\n",
    "We just covered some important topics about writing readable code.  lets practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9923d1-f35a-4b0f-82cf-0c2c330877d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x, y=100):\n",
    "    return x >= y\n",
    "\n",
    "\n",
    "def is_boiling(temp, boiling_point=100):\n",
    "    return temp >= boiling_point\n",
    "\n",
    "\n",
    "def check_if_temperature_is_above_boiling_point(\n",
    "        temperature_to_check, \n",
    "        celsius_water_boiling_point=100):\n",
    "    return temperature_to_check >= celsius_water_boiling_point\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_pizza(ingredients):\n",
    "    # Make dough\n",
    "    dough = mix(ingredients['yeast'], \n",
    "                ingredients['flour'], \n",
    "                ingredients['water'], \n",
    "                ingredients['salt'], \n",
    "                ingredients['shortening'])\n",
    "    \n",
    "    kneaded_dough = knead(dough)\n",
    "    risen_dough = prove(kneaded_dough)\n",
    "    \n",
    "    # Make sauce\n",
    "    sauce_base = sautee(ingredients['onion'], \n",
    "                        ingredients['garlic'], \n",
    "                        ingredients['olive oil'])\n",
    "    \n",
    "    sauce_mixture = combine(sauce_base, \n",
    "                            ingredients['tomato_paste'], \n",
    "                            ingredients['water'], \n",
    "                            ingredients['spices'])\n",
    "    \n",
    "    sauce = simmer(sauce_mixture)\n",
    "    \n",
    "    ......\n",
    "    \n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "def make_pizza(ingredients):\n",
    "    dough = make_dough(ingredients)\n",
    "    sauce = make_sauce(ingredients)\n",
    "    assembled_pizza = assemble_pizza(dough, sauce, ingredients)\n",
    "    \n",
    "    return bake(assembled_pizza)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc9a17-64b3-4549-a741-f4997d760d87",
   "metadata": {},
   "source": [
    "## Using good function names\n",
    "\n",
    "A good function name can go a long way for both user and maintainer understanding. A good function name is descriptive and describes what a function does. In this exercise, you'll choose a name for a function that will help aid in its readability when used.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    The \"math\" module has been pre-loaded into your environment to be able to use its sqrt function.\n",
    "#    Give function the best possible name from the following options: do_stuff, hypotenuse_length, square_root_of_leg_a_squared_plus_leg_b_squared, pythagorean_theorem.\n",
    "    Complete the docstring's example with the function's name.\n",
    "    print the result of using the newly named function to find the length of the hypotenuse for a right triangle with legs of length 6 & 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91484d60-d61f-4602-9747-ea902f7fd994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def hypotenuse_len(leg_a, leg_b):\n",
    "    \"\"\"Find the length of a right triangle's hypotenuse\n",
    "\n",
    "    :param leg_a: length of one leg of triangle\n",
    "    :param leg_b: length of other leg of triangle\n",
    "    :return: length of hypotenuse\n",
    "    \n",
    "    >>> hypotenuse_len(3, 4)\n",
    "    5\n",
    "    \"\"\"\n",
    "    return round(math.sqrt(leg_a * leg_a + leg_b * leg_b))  # You mentioned its 3 times faster, a*a to a**2\n",
    "\n",
    "\n",
    "# Print the length of the hypotenuse with legs 6 & 8\n",
    "print(hypotenuse_len(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6052e4-462e-4081-bf18-2e691d2e94b2",
   "metadata": {},
   "source": [
    "## Using good variable names\n",
    "\n",
    "# Just like functions, descriptive variable names can make your code much more readable. \n",
    "In this exercise, you'll write some code using good variable naming practices.\n",
    "\n",
    "There's not always a clear best name for a variable. The exercise has been written to try and make a clear best choice from the provided options.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "#    Choose the best variable name to hold the sample of pupil diameter measurements in millimeters from the following choices: d, diameter, pupil_diameter, or pupil_diameter_in_millimeters.\n",
    "#    Take the mean of the measurements and assign it to a variable. Choose the best variable name to hold this mean from the following options: m, mean, mean_diameter, or mean_pupil_diameter_in_millimeters.\n",
    "    Print the resulting average pupil diameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a070fc-b62a-4dee-b959-1e3e34ac72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.04\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "# Sample measurements of pupil diameter in mm\n",
    "pupil_diameter = [3.3, 6.8, 7.0, 5.4, 2.7]\n",
    "\n",
    "# Average pupil diameter from sample\n",
    "avg_diameter = mean(pupil_diameter)\n",
    "\n",
    "print(avg_diameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2bb84-4726-4252-b462-cb9b807f6266",
   "metadata": {},
   "source": [
    "## Refactoring for readability\n",
    "\n",
    "# Refactoring longer functions into smaller units can help with both readability and modularity. \n",
    "In this exercise, you will refactor a function into smaller units. The function you will be refactoring is shown below. Note, in the exercise, you won't be using docstrings for the sake of space; in a real application, you should include documentation!\n",
    "\n",
    "def polygon_area(n_sides, side_len):\n",
    "    \"\"\"Find the area of a regular polygon\n",
    "\n",
    "    :param n_sides: number of sides\n",
    "    :param side_len: length of polygon sides\n",
    "    :return: area of polygon\n",
    "\n",
    "    >>> round(polygon_area(4, 5))\n",
    "    25\n",
    "    \"\"\"\n",
    "    perimeter = n_sides * side_len\n",
    "\n",
    "    apothem_denominator = 2 * math.tan(math.pi / n_sides)\n",
    "    apothem = side_len / apothem_denominator\n",
    "\n",
    "    return perimeter * apothem / 2\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Move the logic for calculating the perimeter into the polygon_perimeter function.\n",
    "    Complete the definition of the polygon_apothem function, by moving the logic seen in the context. The math module has already been imported for you.\n",
    "    Utilize the new unit functions to complete the definition of polygon_area.\n",
    "    Use the more unitized polygon_area to calculate the area of a regular hexagon with legs of size 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de918cac-5018-499d-a9c4-073390a658bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259.8076211353316\n",
      "259.8076211353316\n"
     ]
    }
   ],
   "source": [
    "def polygon_area(n_sides, side_len):\n",
    "    \"\"\"Find the area of a regular polygon\n",
    "\n",
    "    :param n_sides: number of sides\n",
    "    :param side_len: length of polygon sides\n",
    "    :return: area of polygon\n",
    "\n",
    "    >>> round(polygon_area(4, 5))\n",
    "    25\n",
    "    \"\"\"\n",
    "    perimeter = n_sides * side_len\n",
    "\n",
    "    apothem_denominator = 2 * math.tan(math.pi / n_sides)\n",
    "    apothem = side_len / apothem_denominator\n",
    "\n",
    "    return perimeter * apothem / 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def polygon_perimeter(n_sides, side_len):\n",
    "    return n_sides * side_len\n",
    "\n",
    "def polygon_apothem(n_sides, side_len):\n",
    "    denominator = 2 * math.tan(math.pi / n_sides)\n",
    "    return side_len / denominator\n",
    "\n",
    "def polygon_area(n_sides, side_len):\n",
    "    perimeter = polygon_perimeter(n_sides, side_len)\n",
    "    apothem = polygon_apothem(n_sides, side_len)\n",
    "\n",
    "    return perimeter * apothem / 2\n",
    "\n",
    "# Print the area of a hexagon with legs of size 10\n",
    "print(polygon_area(n_sides=6, side_len=10))\n",
    "\n",
    "\n",
    "\n",
    "def polygon_perimeter(n_sides, side_len):\n",
    "    return n_sides * side_len\n",
    "\n",
    "def polygon_apothem(n_sides, side_len):\n",
    "    denominator = 2 * math.tan(math.pi / n_sides)\n",
    "    return side_len / denominator\n",
    "\n",
    "def polygon_area(n_sides, side_len):\n",
    "    perimeter = polygon_perimeter(n_sides, side_len)\n",
    "    apothem = polygon_apothem(n_sides, side_len)\n",
    "\n",
    "    return perimeter * apothem / 2\n",
    "\n",
    "# Print the area of a hexagon with legs of size 10\n",
    "print(polygon_area(n_sides=6, side_len=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d578dc-4159-4278-b6ca-9a8949a17024",
   "metadata": {},
   "source": [
    "## Unit testing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Even well-documented, readable code isn't very useful if doesn't work correctly.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "\n",
    "That's where testing can come in handy.  With testing, you can fonfirm your code is working as intended.  You probably run some manual tests.  Instead of writing these tests in the console, you could add much more value to your project by adding these test suite.  \n",
    "\n",
    "A written test can be re-run after you make changes to check if there were any unexpected effects.  Also, changes in dependencies can sometimes break your code.  Automated tests can alert you problems like this and more.  \n",
    "\n",
    "# So how do we test in Python?\n",
    "We'll cover 2 easy to use options: \"doctest\" & \"pytest\".  Thanks to writing informative docstrings with examples included, you've already written tests that can be run with doctest.  Lets look at an example with this square function.  \n",
    "\n",
    "To use doctest we need to import it and run the testmod command to test our module's examples.  When we run the test we see that it failed.  ( did not use round to make return value to int ).  Looks like there was a typo in the docstring example that was caught thanks to doctest.  If there were no failed tests the output testmod would be blank.  \n",
    "\n",
    "\n",
    "# The \"doctest\" are great for smaller examples, but you often can't cover every case you want to test in a docstring.  \n",
    "For example, if your function returns a large Pandas DF this could be hard to include as a doctest.  \n",
    "\n",
    "\n",
    "# For larger cases, there is pytest.  \n",
    "# *******************************************************************************************************************\n",
    "To use pytest, I recommend a tests directory at the same level as your package's directory.  \n",
    "\n",
    "Due to pytest's flexibility, there are other options.  For example, if developing a larger package it might be useful to break out subpackage tests into their own folders.  \n",
    "\n",
    "\n",
    "Lets write some tests for our Document class.  \n",
    "\n",
    "# First, notice the \"test_\" prefix.  The \"pytest\" searches for tests by first looking for files that startor end with the word test, and then pytest runs all the functions in these files who's name follow the same pattern.  \n",
    "\n",
    "Within our test method, we've then created an instance of document as our test case.  Last, we run the actual test with the assert keyword.  As long as the assertion is True, our test passes.  \n",
    "\n",
    "When testing, its also a good idea to test for the edge cases that you can think of.  For example, here we could test the expected attributes of a blank Document.  Note that when testing class objects, its not wise to compare two objects with double equals.  Here we create two identical Document objects and test equality.  Our test shows the objects are not the same.  Instead, to compare objects we can compare attributes as we seen here.  \n",
    "\n",
    "\n",
    "# To run our test we head to the terminal in oour work_dir directory, run the command \"pytest\" and wait for our output.  Jus that simple.  \n",
    "We see that all our tests passed and our code is running as expected.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "# If we just wanted to run the tests in one file, our command might look like this and we'd only get the results for that file's tests.  Powerful right? \n",
    "\n",
    "So far all of our tests have passed.  Lets look at some out put when things go wrong.  In the output, we see exactly  which test failed and even how it failed.  This information can be a lifesaver when your projects grow and tracking down bugs becomes a more time-consuming process.  \n",
    "\n",
    "\n",
    "# Ok, we just covered how-tos and benefits of doctest and pytest.  Lets practice.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ python -m pytest tests/test_document.py \n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.9.2, pytest-7.0.0, pluggy-1.0.0\n",
    "rootdir: /home/jhu/datacmap_data_engineering\n",
    "collected 2 items                                                              \n",
    "\n",
    "tests/test_document.py .F                                                [100%]\n",
    "\n",
    "=================================== FAILURES ===================================\n",
    "_____________________________ test_document_empty ______________________________\n",
    "\n",
    "    def test_document_empty():\n",
    "        doc = Document('')\n",
    "    \n",
    "        assert doc.tokens == []\n",
    ">       assert doc.word_counts == Counter()\n",
    "E       NameError: name 'Counter' is not defined\n",
    "\n",
    "tests/test_document.py:17: NameError\n",
    "=========================== short test summary info ============================\n",
    "FAILED tests/test_document.py::test_document_empty - NameError: name 'Counter...\n",
    "========================= 1 failed, 1 passed in 1.22s ==========================\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ \n",
    "\n",
    "\n",
    "Cause I forgot to import Counter in test file\n",
    "\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ python -m pytest tests/test_document.py \n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.9.2, pytest-7.0.0, pluggy-1.0.0\n",
    "rootdir: /home/jhu/datacmap_data_engineering\n",
    "collected 2 items                                                              \n",
    "\n",
    "tests/test_document.py ..                                                [100%]\n",
    "\n",
    "============================== 2 passed in 1.17s ===============================\n",
    "(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b20b12e7-d176-4890-a928-f8f34f4ee426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x):\n",
    "    \"\"\"Square the number x\n",
    "    \n",
    "    :param x: number to square\n",
    "    \"return: x squared\n",
    "    \n",
    "    >>> square(3)\n",
    "    9\n",
    "    \"\"\"\n",
    "    return x * x\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "567736b2-1899-4f50-a803-73fb1fc35cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def hypotenuse_len(leg_a, leg_b):\n",
    "    \"\"\"Find the length of a right triangle's hypotenuse\n",
    "\n",
    "    :param leg_a: length of one leg of triangle\n",
    "    :param leg_b: length of other leg of triangle\n",
    "    :return: length of hypotenuse\n",
    "    \n",
    "    >>> hypotenuse_len(3, 4)\n",
    "    5\n",
    "    \"\"\"\n",
    "    return round(math.sqrt(leg_a * leg_a + leg_b * leg_b))  # You mentioned its 3 times faster, a*a to a**2\n",
    "\n",
    "\n",
    "# Print the length of the hypotenuse with legs 6 & 8\n",
    "print(hypotenuse_len(3,4))\n",
    "\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b42a4de-c743-4625-87b7-fb44f64c6921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', 'my', 'name', 'is', 'John,', 'nice', 'to', 'meet', 'you.']\n",
      "['Hello,', 'my', 'name', 'is', 'John,', 'nice', 'to', 'meet', 'you.']\n",
      "[]\n",
      "Counter()\n",
      "False\n",
      "<__main__.Document object at 0x7fb1fa085df0>\n",
      "<__main__.Document object at 0x7fb1fa0858e0>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#(datacmap_data_engineering) jhu@debian:~/datacmap_data_engineering$ cat text_analyzer/document.py \n",
    "# Import function to perform tokenization   ### from .token_utils import tokenize\n",
    "from token_utils import tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "\n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        #return tokenize(self.text)\n",
    "        return self.text.split()\n",
    "\n",
    "    # non-public method to tally document's word counts with Counter\n",
    "    def _count_words(self):\n",
    "        #return Counter([i.string for i in self.tokens])\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "\n",
    "    def plot_counter(self, n_most_common=5):\n",
    "        # Subset the n_most_common items from the input Counter object\n",
    "        self.top_items = self.most_common(n_most_common)\n",
    "        # Plot `top_items`\n",
    "        #plot_counter_most_common(top_items)  ##########################################################################\n",
    "\n",
    "        plt.style.use('bmh')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "        ax.bar([i[0] for i in self.top_items],\n",
    "               [i[1] for i in self.top_items])\n",
    "\n",
    "        #plt.title(self, fontsize=14)  how to set the title of each plot?  thinking\n",
    "        #ax.set_xticklabels([i[0] for i in self.top_items], rotation=45)\n",
    "        ax.set_ylabel('Number of counts')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def filter_word_counts(self, first_char):\n",
    "        \"\"\"Pass in a Counter object, filter with 'first_char'\"\"\"\n",
    "        return Counter({ k: v for k, v in self.items() if first_char in k})  ####################################\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "doc = Document('Hello, my name is John, nice to meet you.')\n",
    "print(doc.tokens)\n",
    "\n",
    "\n",
    "hello = 'Hello, my name is John, nice to meet you.'\n",
    "print(hello.split())\n",
    "\n",
    "\n",
    "doc = Document('')\n",
    "print(doc.tokens)\n",
    "\n",
    "print(doc.word_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create 2 identical Document objects\n",
    "doc_a = Document('Hello')\n",
    "doc_b = Document('Hello')\n",
    "\n",
    "\n",
    "# Check if objects are ==\n",
    "print(doc_a == doc_b)  ##############################################################################################\n",
    "print(doc_a)           ##############################################################################################\n",
    "print(doc_b)           ##############################################################################################\n",
    "\n",
    "# Check if attributes are ==\n",
    "print(doc_a.tokens == doc_b.tokens)\n",
    "print(doc_a.word_counts == doc_b.word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e83efe-5086-47c9-8d95-82c11e79ad8a",
   "metadata": {},
   "source": [
    "## Using doctest\n",
    "\n",
    "We just learned about doctest, which, if you're writing full docstrings with examples, is a simple way to minimally test your functions. In this exercise, you'll get some hands-on practice testing and debugging with doctest.\n",
    "\n",
    "The following have all be pre-loaded in your environment: doctest, Counter, and text_analyzer.\n",
    "\n",
    "Note that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.\n",
    "Instructions\n",
    "100 XP\n",
    "\n",
    "    Complete the input code of the example in the docstring for sum_counters.\n",
    "    Complete the docstring example by filling in the expected output.\n",
    "    Run the testmod function from doctest to test your function's example code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1ad81-d54f-498f-b003-8272151c53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_counters(counters):\n",
    "    \"\"\"Aggregate collections.Counter objects by summing counts\n",
    "\n",
    "    :param counters: list/tuple of counters to sum\n",
    "    :return: aggregated counters with counts summed\n",
    "\n",
    "    >>> d1 = text_analyzer.Document('1 2 fizz 4 buzz fizz 7 8')\n",
    "    >>> d2 = text_analyzer.Document('fizz buzz 11 fizz 13 14')\n",
    "    >>> ____([d1.word_counts, d2.word_counts])\n",
    "    ____\n",
    "    \"\"\"\n",
    "    return sum(counters, Counter())\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3c5bd-a6ed-40c0-a94d-70abf76c2318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293842a-14a6-4b8e-8eec-3166262af816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd657b6-c42e-446e-9d70-e3713dddcaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafae1eb-dabd-4c30-9c32-162afcf86544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397402c-1a64-4177-9663-1b096c46b80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fe885-c8ee-461d-ab7a-9164105ded01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7536c8-1db9-4474-9247-e91670a685ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b192d9a-448a-4f80-8c37-3b5186de49cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b668f7b-a036-48a5-befe-c84301908109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95d387-01bb-49d3-83f3-643328191384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
